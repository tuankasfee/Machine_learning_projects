{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "RNA_mutation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "Gw-yP26j0kdL"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUBZ8mzx0kdQ"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "",
        "_uuid": "",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcYu4KKV0kdR",
        "outputId": "f47bc538-737b-43a2-971a-267e10c5846e"
      },
      "source": [
        "dataset = pd.read_csv(\"METABRIC_RNA_Mutation.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (179,189,191,193) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBVsenUX0kdS"
      },
      "source": [
        "# Describing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "QwVh9Mxp0kdS",
        "outputId": "2c44de01-ad85-4054-e142-134556adffb3"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type_of_breast_surgery</th>\n",
              "      <th>cancer_type</th>\n",
              "      <th>cancer_type_detailed</th>\n",
              "      <th>cellularity</th>\n",
              "      <th>pam50_+_claudin-low_subtype</th>\n",
              "      <th>er_status_measured_by_ihc</th>\n",
              "      <th>er_status</th>\n",
              "      <th>neoplasm_histologic_grade</th>\n",
              "      <th>her2_status_measured_by_snp6</th>\n",
              "      <th>her2_status</th>\n",
              "      <th>tumor_other_histologic_subtype</th>\n",
              "      <th>hormone_therapy</th>\n",
              "      <th>inferred_menopausal_state</th>\n",
              "      <th>integrative_cluster</th>\n",
              "      <th>oncotree_code</th>\n",
              "      <th>pr_status</th>\n",
              "      <th>radio_therapy</th>\n",
              "      <th>pik3ca_mut</th>\n",
              "      <th>tp53_mut</th>\n",
              "      <th>muc16_mut</th>\n",
              "      <th>ahnak2_mut</th>\n",
              "      <th>kmt2c_mut</th>\n",
              "      <th>syne1_mut</th>\n",
              "      <th>gata3_mut</th>\n",
              "      <th>map3k1_mut</th>\n",
              "      <th>ahnak_mut</th>\n",
              "      <th>dnah11_mut</th>\n",
              "      <th>cdh1_mut</th>\n",
              "      <th>dnah2_mut</th>\n",
              "      <th>kmt2d_mut</th>\n",
              "      <th>ush2a_mut</th>\n",
              "      <th>ryr2_mut</th>\n",
              "      <th>dnah5_mut</th>\n",
              "      <th>herc2_mut</th>\n",
              "      <th>pde4dip_mut</th>\n",
              "      <th>akap9_mut</th>\n",
              "      <th>tg_mut</th>\n",
              "      <th>birc6_mut</th>\n",
              "      <th>utrn_mut</th>\n",
              "      <th>tbx3_mut</th>\n",
              "      <th>...</th>\n",
              "      <th>hsd17b1</th>\n",
              "      <th>hsd17b10</th>\n",
              "      <th>hsd17b11</th>\n",
              "      <th>hsd17b12</th>\n",
              "      <th>hsd17b13</th>\n",
              "      <th>hsd17b14</th>\n",
              "      <th>hsd17b2</th>\n",
              "      <th>hsd17b3</th>\n",
              "      <th>hsd17b4</th>\n",
              "      <th>hsd17b6</th>\n",
              "      <th>hsd17b7</th>\n",
              "      <th>hsd17b8</th>\n",
              "      <th>hsd3b1</th>\n",
              "      <th>hsd3b2</th>\n",
              "      <th>hsd3b7</th>\n",
              "      <th>mecom</th>\n",
              "      <th>met</th>\n",
              "      <th>ncoa2</th>\n",
              "      <th>nrip1</th>\n",
              "      <th>pik3r3</th>\n",
              "      <th>prkci</th>\n",
              "      <th>prkd1</th>\n",
              "      <th>ran</th>\n",
              "      <th>rdh5</th>\n",
              "      <th>sdc4</th>\n",
              "      <th>serpini1</th>\n",
              "      <th>shbg</th>\n",
              "      <th>slc29a1</th>\n",
              "      <th>sox9</th>\n",
              "      <th>spry2</th>\n",
              "      <th>srd5a1</th>\n",
              "      <th>srd5a2</th>\n",
              "      <th>srd5a3</th>\n",
              "      <th>st7</th>\n",
              "      <th>star</th>\n",
              "      <th>tnk2</th>\n",
              "      <th>tulp4</th>\n",
              "      <th>ugt2b15</th>\n",
              "      <th>ugt2b17</th>\n",
              "      <th>ugt2b7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BREAST CONSERVING</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Invasive Ductal Carcinoma</td>\n",
              "      <td>High</td>\n",
              "      <td>LumA</td>\n",
              "      <td>Positve</td>\n",
              "      <td>Positive</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Ductal/NST</td>\n",
              "      <td>1</td>\n",
              "      <td>Pre</td>\n",
              "      <td>4ER+</td>\n",
              "      <td>IDC</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>H178P</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.4467</td>\n",
              "      <td>-0.0693</td>\n",
              "      <td>-0.7837</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>1.5355</td>\n",
              "      <td>0.7590</td>\n",
              "      <td>-0.5652</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>-1.2693</td>\n",
              "      <td>1.0729</td>\n",
              "      <td>1.1973</td>\n",
              "      <td>-2.9847</td>\n",
              "      <td>-1.9199</td>\n",
              "      <td>0.6433</td>\n",
              "      <td>-0.4801</td>\n",
              "      <td>-1.8732</td>\n",
              "      <td>-1.0840</td>\n",
              "      <td>-0.7220</td>\n",
              "      <td>-0.1878</td>\n",
              "      <td>-1.0623</td>\n",
              "      <td>1.7653</td>\n",
              "      <td>0.3500</td>\n",
              "      <td>-0.2505</td>\n",
              "      <td>-0.6337</td>\n",
              "      <td>-0.1047</td>\n",
              "      <td>0.0222</td>\n",
              "      <td>-0.2938</td>\n",
              "      <td>-1.0821</td>\n",
              "      <td>-1.3206</td>\n",
              "      <td>0.2446</td>\n",
              "      <td>-0.4412</td>\n",
              "      <td>0.4534</td>\n",
              "      <td>0.4068</td>\n",
              "      <td>0.7634</td>\n",
              "      <td>0.0231</td>\n",
              "      <td>0.9121</td>\n",
              "      <td>-0.9538</td>\n",
              "      <td>-0.2264</td>\n",
              "      <td>0.5398</td>\n",
              "      <td>-0.8920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MASTECTOMY</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Invasive Ductal Carcinoma</td>\n",
              "      <td>High</td>\n",
              "      <td>LumB</td>\n",
              "      <td>Positve</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Ductal/NST</td>\n",
              "      <td>1</td>\n",
              "      <td>Pre</td>\n",
              "      <td>3</td>\n",
              "      <td>IDC</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0</td>\n",
              "      <td>H1047R</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.6253</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>1.6822</td>\n",
              "      <td>0.8981</td>\n",
              "      <td>-0.0943</td>\n",
              "      <td>1.1599</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.1493</td>\n",
              "      <td>0.1117</td>\n",
              "      <td>1.6262</td>\n",
              "      <td>2.2685</td>\n",
              "      <td>-0.9910</td>\n",
              "      <td>0.1767</td>\n",
              "      <td>-0.9128</td>\n",
              "      <td>-0.0006</td>\n",
              "      <td>0.7079</td>\n",
              "      <td>-0.7401</td>\n",
              "      <td>1.2279</td>\n",
              "      <td>-0.2882</td>\n",
              "      <td>-0.1727</td>\n",
              "      <td>1.1257</td>\n",
              "      <td>0.8306</td>\n",
              "      <td>0.2707</td>\n",
              "      <td>-0.7554</td>\n",
              "      <td>-0.3559</td>\n",
              "      <td>-0.7735</td>\n",
              "      <td>-0.1387</td>\n",
              "      <td>-0.9122</td>\n",
              "      <td>1.2552</td>\n",
              "      <td>0.4593</td>\n",
              "      <td>-0.5381</td>\n",
              "      <td>0.0668</td>\n",
              "      <td>0.8344</td>\n",
              "      <td>1.7227</td>\n",
              "      <td>0.4024</td>\n",
              "      <td>-3.7172</td>\n",
              "      <td>-1.5538</td>\n",
              "      <td>1.3701</td>\n",
              "      <td>-0.1078</td>\n",
              "      <td>0.3655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MASTECTOMY</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Mixed Ductal and Lobular Carcinoma</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>LumB</td>\n",
              "      <td>Positve</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>1</td>\n",
              "      <td>Pre</td>\n",
              "      <td>9</td>\n",
              "      <td>MDLC</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>E542K</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.8189</td>\n",
              "      <td>0.0960</td>\n",
              "      <td>1.4099</td>\n",
              "      <td>-0.6707</td>\n",
              "      <td>-0.3589</td>\n",
              "      <td>-0.8998</td>\n",
              "      <td>-0.5063</td>\n",
              "      <td>0.2546</td>\n",
              "      <td>-0.6586</td>\n",
              "      <td>1.7024</td>\n",
              "      <td>0.1617</td>\n",
              "      <td>1.4208</td>\n",
              "      <td>0.1320</td>\n",
              "      <td>1.8754</td>\n",
              "      <td>-1.8850</td>\n",
              "      <td>0.1474</td>\n",
              "      <td>0.5097</td>\n",
              "      <td>-0.0393</td>\n",
              "      <td>-0.2049</td>\n",
              "      <td>-0.3290</td>\n",
              "      <td>3.2140</td>\n",
              "      <td>2.4162</td>\n",
              "      <td>1.7962</td>\n",
              "      <td>-1.2505</td>\n",
              "      <td>-0.1742</td>\n",
              "      <td>-0.2858</td>\n",
              "      <td>-0.7305</td>\n",
              "      <td>-1.0178</td>\n",
              "      <td>-0.7887</td>\n",
              "      <td>1.3361</td>\n",
              "      <td>-0.5630</td>\n",
              "      <td>-0.7078</td>\n",
              "      <td>0.8228</td>\n",
              "      <td>0.6819</td>\n",
              "      <td>-0.1948</td>\n",
              "      <td>-2.3286</td>\n",
              "      <td>-0.9924</td>\n",
              "      <td>-0.3154</td>\n",
              "      <td>0.2320</td>\n",
              "      <td>-0.4828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MASTECTOMY</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Mixed Ductal and Lobular Carcinoma</td>\n",
              "      <td>High</td>\n",
              "      <td>LumB</td>\n",
              "      <td>Positve</td>\n",
              "      <td>Positive</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>1</td>\n",
              "      <td>Post</td>\n",
              "      <td>9</td>\n",
              "      <td>MDLC</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S241F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>F2321Y</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0590</td>\n",
              "      <td>0.2796</td>\n",
              "      <td>0.0493</td>\n",
              "      <td>-0.7074</td>\n",
              "      <td>0.0696</td>\n",
              "      <td>-0.4491</td>\n",
              "      <td>-0.5634</td>\n",
              "      <td>-0.7627</td>\n",
              "      <td>-0.7051</td>\n",
              "      <td>0.6065</td>\n",
              "      <td>-0.0141</td>\n",
              "      <td>0.7040</td>\n",
              "      <td>-2.0938</td>\n",
              "      <td>-0.1260</td>\n",
              "      <td>-0.6658</td>\n",
              "      <td>0.6451</td>\n",
              "      <td>0.5497</td>\n",
              "      <td>4.1999</td>\n",
              "      <td>0.2832</td>\n",
              "      <td>0.4018</td>\n",
              "      <td>0.1308</td>\n",
              "      <td>-0.5351</td>\n",
              "      <td>1.2930</td>\n",
              "      <td>1.2971</td>\n",
              "      <td>-0.8885</td>\n",
              "      <td>-0.5545</td>\n",
              "      <td>0.0266</td>\n",
              "      <td>0.5328</td>\n",
              "      <td>0.1858</td>\n",
              "      <td>-0.3201</td>\n",
              "      <td>-0.5845</td>\n",
              "      <td>-0.3544</td>\n",
              "      <td>-1.0150</td>\n",
              "      <td>2.2961</td>\n",
              "      <td>0.1817</td>\n",
              "      <td>-0.1572</td>\n",
              "      <td>0.0427</td>\n",
              "      <td>5.0048</td>\n",
              "      <td>3.8476</td>\n",
              "      <td>1.3223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MASTECTOMY</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Invasive Ductal Carcinoma</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>LumB</td>\n",
              "      <td>Positve</td>\n",
              "      <td>Positive</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Ductal/NST</td>\n",
              "      <td>1</td>\n",
              "      <td>Post</td>\n",
              "      <td>7</td>\n",
              "      <td>IDC</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>H1047R</td>\n",
              "      <td>P67Qfs*56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A318T</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.4705</td>\n",
              "      <td>0.0219</td>\n",
              "      <td>0.8457</td>\n",
              "      <td>0.2548</td>\n",
              "      <td>-0.4682</td>\n",
              "      <td>-0.7314</td>\n",
              "      <td>-0.3240</td>\n",
              "      <td>-0.3282</td>\n",
              "      <td>1.1360</td>\n",
              "      <td>1.5011</td>\n",
              "      <td>-0.4428</td>\n",
              "      <td>0.6873</td>\n",
              "      <td>0.1311</td>\n",
              "      <td>-0.4149</td>\n",
              "      <td>-0.9105</td>\n",
              "      <td>-0.8526</td>\n",
              "      <td>-0.7718</td>\n",
              "      <td>0.0466</td>\n",
              "      <td>-0.1657</td>\n",
              "      <td>1.0143</td>\n",
              "      <td>1.3033</td>\n",
              "      <td>1.3506</td>\n",
              "      <td>0.2875</td>\n",
              "      <td>-1.0378</td>\n",
              "      <td>1.1967</td>\n",
              "      <td>-0.3843</td>\n",
              "      <td>0.4306</td>\n",
              "      <td>0.0314</td>\n",
              "      <td>0.6884</td>\n",
              "      <td>-0.4448</td>\n",
              "      <td>-0.3910</td>\n",
              "      <td>0.0395</td>\n",
              "      <td>0.8191</td>\n",
              "      <td>0.1977</td>\n",
              "      <td>-0.2302</td>\n",
              "      <td>-0.5092</td>\n",
              "      <td>-0.3021</td>\n",
              "      <td>0.9357</td>\n",
              "      <td>-0.4217</td>\n",
              "      <td>0.5340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 684 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  type_of_breast_surgery    cancer_type  ... ugt2b17  ugt2b7\n",
              "1      BREAST CONSERVING  Breast Cancer  ...  0.5398 -0.8920\n",
              "2             MASTECTOMY  Breast Cancer  ... -0.1078  0.3655\n",
              "3             MASTECTOMY  Breast Cancer  ...  0.2320 -0.4828\n",
              "4             MASTECTOMY  Breast Cancer  ...  3.8476  1.3223\n",
              "5             MASTECTOMY  Breast Cancer  ... -0.4217  0.5340\n",
              "\n",
              "[5 rows x 684 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JKPH-Xc0kdT",
        "outputId": "94e01a54-5983-497e-8301-fde07190e553"
      },
      "source": [
        "print(dataset.shape)\n",
        "dataset.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1904, 688)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type_of_breast_surgery          object\n",
              "cancer_type                     object\n",
              "cancer_type_detailed            object\n",
              "cellularity                     object\n",
              "pam50_+_claudin-low_subtype     object\n",
              "                                ...   \n",
              "tnk2                           float64\n",
              "tulp4                          float64\n",
              "ugt2b15                        float64\n",
              "ugt2b17                        float64\n",
              "ugt2b7                         float64\n",
              "Length: 688, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Yz1z-xWCnj"
      },
      "source": [
        "# Check missing value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bD4t9whSa56",
        "outputId": "ca80c509-aefd-4d10-a66e-4f9678d889df"
      },
      "source": [
        "miss_value = {}\n",
        "for column in dataset.columns:\n",
        "  count = dataset[column].isnull().sum()\n",
        "  if count >0:\n",
        "    miss_value[column] = count\n",
        "\n",
        "print(miss_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'type_of_breast_surgery': 22, 'cancer_type_detailed': 15, 'cellularity': 54, 'er_status_measured_by_ihc': 30, 'neoplasm_histologic_grade': 72, 'tumor_other_histologic_subtype': 15, 'primary_tumor_laterality': 106, 'oncotree_code': 15, '3-gene_classifier_subtype': 204, 'tumor_stage': 501, 'mutation_count': 45, 'tumor_size': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVqEL8sQ5Mz5"
      },
      "source": [
        "# Drop missing value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqV5cY-iE9IJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f534eb-0ffc-46b0-fcc8-350a5c306144"
      },
      "source": [
        "dataset = dataset.drop(['3-gene_classifier_subtype','tumor_stage','primary_tumor_laterality'],axis='columns')\n",
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1904, 685)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIXc-Jl90kdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9f9f1b-ad59-40dc-95a2-a71098888f05"
      },
      "source": [
        "dataset = dataset.dropna(axis='rows')\n",
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677, 685)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cal0JcGyWXs0"
      },
      "source": [
        "# Create target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZmBC2F8Rtij"
      },
      "source": [
        "y = dataset['overall_survival']\n",
        "dataset = dataset.drop('overall_survival', axis ='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui7tG2im5WdH"
      },
      "source": [
        "# Check type of value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoGXzZBi1b-c",
        "outputId": "aa7f4d62-f2f3-418b-d3e1-bea357580377"
      },
      "source": [
        "dataset['smarcb1_mut'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       878\n",
              "0       798\n",
              "I28L      1\n",
              "Name: smarcb1_mut, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDYr01S30kdV"
      },
      "source": [
        "list_cat = []\n",
        "for column in dataset.columns:\n",
        "    if column == 'age_at_diagnosis':\n",
        "      break\n",
        "    else:\n",
        "      list_cat.append(column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1shoIDbK0kdV"
      },
      "source": [
        "for column in list_cat:\n",
        "    dataset[column] = dataset[column].replace([0],'0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STPpoZP4WweF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50b68d0-47c1-457b-98bf-1990be89845e"
      },
      "source": [
        "dataset['smarcb1_mut'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1676\n",
              "I28L       1\n",
              "Name: smarcb1_mut, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnpoBkKp5gLD"
      },
      "source": [
        "# Create clean dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3OziE6R0kdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1895cee2-3560-44df-9924-53efbf2d4f2d"
      },
      "source": [
        "dataset_new = pd.get_dummies(dataset,columns=list_cat)\n",
        "dataset_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677, 7761)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xea-2oGC0kdX"
      },
      "source": [
        "dataset_new = dataset_new.astype(np.float16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeQzUyVi2JBg"
      },
      "source": [
        "# Create feature and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTqQdBnb0kdY",
        "outputId": "2ec249fc-9df6-4914-9973-7e2ccdcc0e07"
      },
      "source": [
        "x = dataset_new.values\n",
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677, 7761)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEIUYaAp0kdZ",
        "outputId": "1174733f-aba3-41f3-d4d8-821b62ff60a9"
      },
      "source": [
        "labelencoder= LabelEncoder()\n",
        "y = labelencoder.fit_transform(y)\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ3ibAI82ad-"
      },
      "source": [
        "# Split train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYKv4mZF0kdZ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoXyO6pnYhVm"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2l9Q9Gb0kdZ",
        "outputId": "5648f77d-cc26-4206-e880-5008a4053d5c"
      },
      "source": [
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfjr2xnQ0kda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41d161b-c387-42aa-d94a-d6e5ac98e982"
      },
      "source": [
        "y_pred = svclassifier.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[155  41]\n",
            " [ 61  79]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.79      0.75       196\n",
            "           1       0.66      0.56      0.61       140\n",
            "\n",
            "    accuracy                           0.70       336\n",
            "   macro avg       0.69      0.68      0.68       336\n",
            "weighted avg       0.69      0.70      0.69       336\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0h2fREQZg87"
      },
      "source": [
        "# Experiment 1: without scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jl82MB880kdd",
        "outputId": "11f61133-906e-4868-dbe3-5bc607fbf506"
      },
      "source": [
        "# keeping all models in one list\n",
        "models=[]\n",
        "models.append(('LogisticRegression',LogisticRegression()))\n",
        "models.append(('knn',KNeighborsClassifier(n_neighbors=5)))\n",
        "models.append(('SVC',SVC()))\n",
        "models.append((\"decision_tree\",DecisionTreeClassifier()))\n",
        "models.append(('Naive Bayes',GaussianNB()))\n",
        "\n",
        "# Evaluating Each model\n",
        "predictions=[]\n",
        "experiment_1 = {}\n",
        "error='accuracy'\n",
        "for name,model in models:\n",
        "    fold=KFold(n_splits=10)\n",
        "    result=cross_val_score(model,x,y,cv=fold,scoring=error)\n",
        "    predictions.append(result)\n",
        "    experiment_1[name] = result.mean()\n",
        "\n",
        "# Visualizing the Model accuracy\n",
        "fig=plt.figure()\n",
        "fig.suptitle(\"Comparing Algorithms\")\n",
        "plt.boxplot(predictions)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "asvdn2mln3pa",
        "outputId": "e843a6d5-b697-4ab6-c468-228443ae774f"
      },
      "source": [
        "\n",
        "pd.DataFrame([experiment_1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>knn</th>\n",
              "      <th>SVC</th>\n",
              "      <th>decision_tree</th>\n",
              "      <th>Naive Bayes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.66841</td>\n",
              "      <td>0.69403</td>\n",
              "      <td>0.596339</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   LogisticRegression      knn      SVC  decision_tree  Naive Bayes\n",
              "0            0.642212  0.66841  0.69403       0.596339     0.582007"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZiJO1E70kde"
      },
      "source": [
        "# Experiment 2: with scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "diflib2H0kde",
        "outputId": "798f24c0-f1cb-45d5-e109-98e6951c0a50"
      },
      "source": [
        "# Spot Checking and Comparing Algorithms With StandardScaler Scaler\n",
        "pipelines=[]\n",
        "pipelines.append(('scaled Logisitic Regression',Pipeline([('scaler',StandardScaler()),('LogisticRegression',LogisticRegression())])))\n",
        "pipelines.append(('scaled KNN',Pipeline([('scaler',StandardScaler()),('KNN',KNeighborsClassifier(n_neighbors=5))])))\n",
        "pipelines.append(('scaled SVC',Pipeline([('scaler',StandardScaler()),('SVC',SVC())])))\n",
        "pipelines.append(('scaled DecisionTree',Pipeline([('scaler',StandardScaler()),('decision',DecisionTreeClassifier())])))\n",
        "pipelines.append(('scaled naive bayes',Pipeline([('scaler',StandardScaler()),('scaled Naive Bayes',GaussianNB())])))\n",
        "\n",
        "# Evaluating Each model\n",
        "predictions=[]\n",
        "experiment_2 = {}\n",
        "for name,model in models:\n",
        "    fold=KFold(n_splits=10)\n",
        "    result=cross_val_score(model,x,y,cv=fold,scoring=error)\n",
        "    predictions.append(result)\n",
        "    experiment_2[name] = result.mean()\n",
        "\n",
        "# Visualizing the Model accuracy\n",
        "fig=plt.figure()\n",
        "fig.suptitle(\"Comparing Algorithms\")\n",
        "plt.boxplot(predictions)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "gkCGWd3ZqbU5",
        "outputId": "95c682eb-422b-4c27-a589-3cb78f6e23eb"
      },
      "source": [
        "pd.DataFrame([experiment_1, experiment_2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>knn</th>\n",
              "      <th>SVC</th>\n",
              "      <th>decision_tree</th>\n",
              "      <th>Naive Bayes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.66841</td>\n",
              "      <td>0.69403</td>\n",
              "      <td>0.596339</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.66841</td>\n",
              "      <td>0.69403</td>\n",
              "      <td>0.591574</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   LogisticRegression      knn      SVC  decision_tree  Naive Bayes\n",
              "0            0.642212  0.66841  0.69403       0.596339     0.582007\n",
              "1            0.642212  0.66841  0.69403       0.591574     0.582007"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U648U3U8ZwTX"
      },
      "source": [
        "# Experiment 3: dimensional reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMqwHqwy-mOg"
      },
      "source": [
        "pca = PCA(n_components=500)\n",
        "new_x = pca.fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abEcyz7K-0M-",
        "outputId": "4d39a627-91e0-47ad-a53e-4a173c76dccf"
      },
      "source": [
        "sum = 0\n",
        "for i in pca.explained_variance_ratio_:\n",
        "  sum = sum +i\n",
        "\n",
        "print(\"Overall variation :\", sum)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall variation : 0.992588985266454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW0P9EyD_DV9",
        "outputId": "4d777d88-0414-4488-8a73-d0815b070d97"
      },
      "source": [
        "new_x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cd-YKQEg_tV2",
        "outputId": "e84c1de1-ef67-4617-88fa-5d04cc6746e6"
      },
      "source": [
        "# Spotcheck and compare algorithms with out applying feature scale.......\n",
        "n_neighbors=5\n",
        "\n",
        "# keeping all models in one list\n",
        "models=[]\n",
        "models.append(('LogisticRegression',LogisticRegression()))\n",
        "models.append(('knn',KNeighborsClassifier(n_neighbors=n_neighbors)))\n",
        "models.append(('SVC',SVC()))\n",
        "models.append((\"decision_tree\",DecisionTreeClassifier()))\n",
        "models.append(('Naive Bayes',GaussianNB()))\n",
        "\n",
        "# Evaluating Each model\n",
        "predictions=[]\n",
        "error='accuracy'\n",
        "experiment_3 = {}\n",
        "for name,model in models:\n",
        "    fold=KFold(n_splits=10)\n",
        "    result=cross_val_score(model,new_x,y,cv=fold,scoring=error)\n",
        "    predictions.append(result)\n",
        "    experiment_3[name] = result.mean()\n",
        "\n",
        "# Visualizing the Model accuracy\n",
        "fig=plt.figure()\n",
        "fig.suptitle(\"Comparing Algorithms\")\n",
        "plt.boxplot(predictions)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEVCAYAAADuAi4fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZ4klEQVR4nO3df5RXd33n8efLgQSrSZxZUFMggA2x0x01Md9Su0EbapOg9YS0npNCtBJ3FLtHxl+7WrJjG4LS2j1HzVmWnorCao9m0MY2i1vbmHMyrB3XWL6kGAOYSNCUwUQmzKRpusEMk/f+8b3A5cvMfL/DfIf75TOvxzn38L33fu6973sneX3v93Pv93sVEZiZWbpeVHQBZmY2tRz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJc9BbMiS9Q9K3Ctr2FyV9corWPe5+SbpWUv9UbNvS4KC3M0i6RVJZ0rOSnpD0d5KWFl1XLRHxlYi4fiq3IWmnpCFJF07ldvKq90tSSLr8XG3fzn8OejuNpI8AdwJ/ArwCuAz4c2BFkXXVImnGOdjGQuCNQAA3TvX2sm1O+X5Z+hz0dpKkS4ANwPsj4q8j4t8iYjgivhERH83aXCjpTkk/zYY7T5zdnuhCkPQxSUeyTwM3SXqrpEclDUr6r7ntrZd0t6SvSvpXSQ9Kel1u/jpJj2Xz9kn6ndy8WyV9R9JnJR0F1mfT+nJtQtIfSPqRpKclbZakbF6LpE9LekrSjyWtzdqPF6zvAh4AvgisrnEsP5bt/08lvSd/Fi7pEkl/KWlA0uOSPi7pRfXsl6RvZ5v4fvaJ6/dy2/zPueP+7tz0L0r68+yT2bPZ+l+Z/e2GJP1Q0lW59n8o6XB23B+R9Obx9tWan4Pe8n4dmAX8zThtuoE3AFcCrwOWAB/PzX9lto65wB8DnwfeCVxN5Wz4jyQtyrVfAfwV0AbcBdwjaWY277FsmUuAO4AvS7o0t+yvAQepfPLYOEa9bwN+FXgtcDNwQzb9vcBbsv14PXDTOPt8wruAr2TDDZJeMVojScuBjwC/BVwOXFvVZFO2T68CfiNb77tz88fcr4h4U/bydRHx0oj4ajb+ymydc4FOYLOk1tyiN1P5O80Gfg58F3gwG78b+ExW+6uBtcCvRsRFVI7XT8Y+JHZeiAgPHogIgHcAT9Zo8xjw1tz4DcBPstfXAs8BLdn4RVS6OX4t1343cFP2ej3wQG7ei4AngDeOse09wIrs9a3AP1fNvxXoy40HsDQ3/jVgXfb6fuB9uXm/lbWfMca2lwLDwOxs/IfAh3Pzvwh8Mnu9DfjT3LzLs3VfDrQAzwO/kpv/PmDnBPfr8tz4ieM+IzftCPCGXG2fz83rAvbnxl8DPJ2r9Uh2PGYW/d+kh8YMPqO3vKPA7BrdF78IPJ4bfzybdnIdETGSvX4u+/dnufnPAS/NjR868SIiXgD6T6xP0rsk7cm6XZ4GOqicgZ6x7DiezL3+f7lt/2LV8rXWtRr4VkQ8lY3fxdjdN+OtezYwkzOP4dwJ1DKaoxFxPDee31c4828w6t8kIg4AH6LyJnxE0nZJ+b+vnYcc9Jb3XSof68frxvgpsCA3flk27WzNP/Ei66eeB/xU0gIq3T5rgX8XES8DHgaUW3YyP736RLatM+qoJunFVLo+fkPSk5KeBD4MvC5/TaHOdT9F5ZNB9TE8nBsv9CdlI+KuiFhKpcYA/qzIemzyHPR2UkT8C5V+9c3ZRdRfkDRT0lsk/besWQ/wcUlzJM3O2n95Epu9WtLvZp8iPkTljeYB4CVUQmYAILu42DGJ7VT7GvBBSXMlvQz4w3Ha3gSMAL9CpU//SqAd+Acq/eujrfvdktol/QLwRydmZJ92vgZslHRR9ob2ESZ2DH9GpX+/4SS9WtJvZhfYj1E5239hKrZl546D3k4TEZ+mEjwfpxKyh6icVd+TNfkkUAYeAn5A5YLeZL4o9L+A3wOGgN8Hfjcqd/rsAz5N5VPGz6j0I39nEtup9nngW1T245+AbwLHqQR6tdXA/4yIf46IJ08MwP8A3lHd1RURfwf8d6AXOEDljQsqb2JQ6SP/NyoXXPuodANtm0Dt64EvZV1aN09guXpcCHyKyiePJ4GXA7c1eBt2jinCDx6xYkhaT+Wi4juboJa3AH8REQtqNp74utupdDtdWNWPbnZO+IzepiVJL87u758haS5wO+PfVjrR9f+OKt85aKXSx/0Nh7wVxUFv05Wo3Js/RKXrZj+V6w2N8j4qtyk+RqU76D81cN1mE+KuGzOzxPmM3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEOejNzBLnoDczS5yD3swscQ56M7PEzajd5NyaPXt2LFy4sOgyzMzOK7t3734qIuaMNq/pgn7hwoWUy+WiyzAzO69Ienysee66MTNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEtd0X5gyK4qkhqwnIhqyHrNGcdCbZeoJaEkOcjvvuOvGzCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxdQW9pOWSHpF0QNK6UeZ/VtKebHhU0tO5eSO5eTsaWbyZmdVW82eKJbUAm4HrgH5gl6QdEbHvRJuI+HCufRdwVW4Vz0XElY0r2czMJqKeM/olwIGIOBgRzwPbgRXjtF8F9DSiODMzm7x6gn4ucCg33p9NO4OkBcAi4P7c5FmSypIekHTTGMutydqUBwYG6izdzMzq0eiLsSuBuyNiJDdtQUSUgFuAOyX9UvVCEbElIkoRUZozZ06DSzIzm97qCfrDwPzc+Lxs2mhWUtVtExGHs38PAjs5vf/ezMymWD1BvwtYLGmRpAuohPkZd89I+mWgFfhublqrpAuz17OBa4B91ctasSRNejCz5lXzrpuIOC5pLXAv0AJsi4i9kjYA5Yg4Eforge1x+pOT24HPSXqBypvKp/J361hzqPWw61QeiN3W1sbQ0NCk1zPZN7bW1lYGBwcnXYdZvdRs/wOXSqUol8tFl2E5qQR9s+xHs9RhaZG0O7seegZ/M9bMLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56A3M0ucg97MLHEOejOzxDnozcwS56Cv0tPTQ0dHBy0tLXR0dNDT01N0SWZmk1JX0EtaLukRSQckrRtl/mcl7cmGRyU9nZu3WtKPsmF1I4tvtJ6eHrq7u9m0aRPHjh1j06ZNdHd3O+zN7LymWk+jl9QCPApcB/QDu4BVEbFvjPZdwFUR8R8ltQFloAQEsBu4OiKGxtpeqVSKcrl8NvsyaR0dHWzatIlly5adnNbb20tXVxcPP/xwITU1A0nU+u/kvLD+kqIrOGX9vxRdgSVG0u6IKI06r46g/3VgfUTckI3fBhARfzpG+/8L3B4R90laBVwbEe/L5n0O2BkRY54iFxn0LS0tHDt2jJkzZ56cNjw8zKxZsxgZGSmkpslqa2tjaGjM99VzprW1lcHBwUJraJY3rGapw9IyXtDX03UzFziUG+/Ppo22oQXAIuD+iS7bDNrb2+nr6zttWl9fH+3t7QVVNHlDQ0NEROFDM7zZmE1Xjb4YuxK4OyImdPoraY2ksqTywMBAg0uqX3d3N52dnfT29jI8PExvby+dnZ10d3cXVpOZ2WTNqKPNYWB+bnxeNm00K4H3Vy17bdWyO6sXiogtwBaodN3UUdOUWLVqFQBdXV3s37+f9vZ2Nm7ceHK6mdn5qJ4++hlULsa+mUpw7wJuiYi9Ve1+Gfh7YFFkK80uxu4GXp81e5DKxdgxO2uL7KNPUbP0BzdDHc1QQzPVYWkZr4++5hl9RByXtBa4F2gBtkXEXkkbgHJE7MiargS2R+6/4IgYlPQJKm8OABvGC3kzM2u8mmf055rP6BurWc4em6GOZqihmeqwtEz2rhszMzuPOejNzBLnoDczS5yD3swscfXcR29mNm1Jash6irwA76A3MxtHPQHd7HdSuevGzCxxDnozs8Q56M3MEuc++sTF7Rc3xQM34vaLiy7BbNpy0CdOdzzTFBeJJBHri67CbHpy142ZWeIc9GZmiXPQm5klzkFvZpY4X4y1aaVRX2efjNbW1qJLsGnGQW/TRiPuPmr2r7qbjcZdN2ZmifMZvZmdIYVfbLRTHPRmdoYUfrHRTnHXjZlZ4uoKeknLJT0i6YCkdWO0uVnSPkl7Jd2Vmz4iaU827GhU4WZmVp+aXTeSWoDNwHVAP7BL0o6I2Jdrsxi4DbgmIoYkvTy3iuci4soG121mZnWq54x+CXAgIg5GxPPAdmBFVZv3ApsjYgggIo40tkwzMztb9QT9XOBQbrw/m5Z3BXCFpO9IekDS8ty8WZLK2fSbRtuApDVZm/LAwMCEdsDMzMbXqLtuZgCLgWuBecC3Jb0mIp4GFkTEYUmvAu6X9IOIeCy/cERsAbYAlEolX8Y3M2uges7oDwPzc+Pzsml5/cCOiBiOiB8Dj1IJfiLicPbvQWAncNUkazYzswmoJ+h3AYslLZJ0AbASqL575h4qZ/NImk2lK+egpFZJF+amXwPsw8zMzpmaXTcRcVzSWuBeoAXYFhF7JW0AyhGxI5t3vaR9wAjw0Yg4Kuk/AJ+T9AKVN5VP5e/WKVIjvvnnL4uY2flAzRZWpVIpyuXypNbR1tbG0NBQgyo6e62trQwODhZaQ7N8e7FZ6pisVPajEXwsTmmGYyFpd0SURpuX5E8gDA0NFX7QoTl+EtfMzD+BYGaWOAe9mVnikuy6idsvhvWXFF1GpY4m0AxdSH6qkllxkgx63fFM0/TRx/pia/BTlczMXTdmZolz0JuZJc5Bb2aWuCT76MEXIM2sPo36guVkM2cqv2CZZND7AqSZ1Ws6fMHSXTdmZolz0JuZJc5Bb2aWOAe9mVnikrwYW496LnzUatMMF3DMzGqZtkHvkDaz6cJdN2ZmiXPQm5klzkFvZpY4B72ZWeLqCnpJyyU9IumApHVjtLlZ0j5JeyXdlZu+WtKPsmF1owo3azRJNYd62pk1m5p33UhqATYD1wH9wC5JOyJiX67NYuA24JqIGJL08mx6G3A7UAIC2J0tO/lfEDJrMN+JZamq54x+CXAgIg5GxPPAdmBFVZv3AptPBHhEHMmm3wDcFxGD2bz7gOWNKd3MzOpRT9DPBQ7lxvuzaXlXAFdI+o6kByQtn8CyZnaOtbW11dVVNdlurFpDW1tbwUdiemjUF6ZmAIuBa4F5wLclvabehSWtAdYAXHbZZQ0qyczGMviBEaAZHl4/UnQB00I9QX8YmJ8bn5dNy+sHvhcRw8CPJT1KJfgPUwn//LI7qzcQEVuALQClUskdpWZTTHc80xTXJCQR64uuIn31dN3sAhZLWiTpAmAlsKOqzT1kgS5pNpWunIPAvcD1kloltQLXZ9PMzOwcqXlGHxHHJa2lEtAtwLaI2CtpA1COiB2cCvR9VD6LfTQijgJI+gSVNwuADRExNc/KMjOzUakZPr7llUqlKJfLRZdhOX6sYnqa5W/aDHU0Qw2NqEPS7ogojTbP34w1M0ucg97MLHEOejOzxDnozcwS56A3M0ucg75KT08PHR0dtLS00NHRQU9PT9ElTTn/YqNZ2qbtM2NH09PTQ3d3N1u3bmXp0qX09fXR2dkJwKpVqwqubuo0w61lZkWJ2y+G9ZcUXUaljini++hzOjo62LRpE8uWLTs5rbe3l66uLh5++OFCajKbCqncO55KDY2oY7z76B30OS0tLRw7doyZM2eenDY8PMysWbMYGfGPL1k6Ugm3VGpoRB3+wlSd2tvb6evrO21aX18f7e3tBVVkZjZ5Dvqc7u5uOjs76e3tZXh4mN7eXjo7O+nu7i66NDOzs+aLsTknLrh2dXWxf/9+2tvb2bhxY9IXYs0sfe6jN5uGUumXTqWGRtThPnozs2nMQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4hz0ZmaJqyvoJS2X9IikA5LWjTL/VkkDkvZkw3ty80Zy03c0sngzM6ut5k8gSGoBNgPXAf3ALkk7ImJfVdOvRsTaUVbxXERcOflSzayRmuGBMa2trUWXMC3U81s3S4ADEXEQQNJ2YAVQHfRmdp5oxFf+m+WnAxoh9Te9erpu5gKHcuP92bRqb5f0kKS7Jc3PTZ8lqSzpAUk3jbYBSWuyNuWBgYH6qzczm6SImPTQiPUMDg5O2T426mLsN4CFEfFa4D7gS7l5C7If2rkFuFPSL1UvHBFbIqIUEaU5c+Y0qCQzM4P6gv4wkD9Dn5dNOykijkbEz7PRLwBX5+Ydzv49COwErppEvWZmNkH1BP0uYLGkRZIuAFYCp909I+nS3OiNwP5sequkC7PXs4FrcN++mdk5VfNibEQcl7QWuBdoAbZFxF5JG4ByROwAPiDpRuA4MAjcmi3eDnxO0gtU3lQ+NcrdOmbWZOq9OFmrXSoXa893fvCImdkkNcMdSH7wiJnZNOagNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEldX0EtaLukRSQckrRtl/q2SBiTtyYb35OatlvSjbFjdyOLNzKy2GbUaSGoBNgPXAf3ALkk7ImJfVdOvRsTaqmXbgNuBEhDA7mzZoYZUb2ZmNdVzRr8EOBARByPieWA7sKLO9d8A3BcRg1m43wcsP7tSzczsbNQT9HOBQ7nx/mxatbdLekjS3ZLmT2RZSWsklSWVBwYG6izdzMzq0aiLsd8AFkbEa6mctX9pIgtHxJaIKEVEac6cOQ0qyczMoL6gPwzMz43Py6adFBFHI+Ln2egXgKvrXdbMzKZWPUG/C1gsaZGkC4CVwI58A0mX5kZvBPZnr+8FrpfUKqkVuD6bZmZm50jNu24i4riktVQCugXYFhF7JW0AyhGxA/iApBuB48AgcGu27KCkT1B5swDYEBGDU7AfZmY2BkVE0TWcplQqRblcLroMM7O6SaLoLJW0OyJKo83zN2PNzBLnoDczS5yD3swscTUvxpqZTWeSGtKuyD58B72Z2TiKvsjaCO66MTNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8TVFfSSlkt6RNIBSevGafd2SSGplI0vlPScpD3Z8BeNKtzMzOpT88EjklqAzcB1QD+wS9KOiNhX1e4i4IPA96pW8VhEXNmges3MbILqOaNfAhyIiIMR8TywHVgxSrtPAH8GHGtgfWZmNkn1BP1c4FBuvD+bdpKk1wPzI+JvR1l+kaR/kvR/JL3x7Es1s2bQ09NDR0cHLS0tdHR00NPTU3RJVsOknxkr6UXAZ4BbR5n9BHBZRByVdDVwj6R/HxHPVK1jDbAG4LLLLptsSWY2RXp6euju7mbr1q0sXbqUvr4+Ojs7AVi1alXB1dlY6jmjPwzMz43Py6adcBHQAeyU9BPgDcAOSaWI+HlEHAWIiN3AY8AV1RuIiC0RUYqI0pw5c85uT8xsym3cuJGtW7eybNkyZs6cybJly9i6dSsbN24sujQbh2o94VzSDOBR4M1UAn4XcEtE7B2j/U7gv0REWdIcYDAiRiS9CvgH4DURMTjW9kqlUpTL5bPaGTObWi0tLRw7doyZM2eenDY8PMysWbMYGRkpsDKTtDsiSqPNq3lGHxHHgbXAvcB+4GsRsVfSBkk31lj8TcBDkvYAdwN/MF7Im1lza29vp6+v77RpfX19tLe3F1SR1aOuPvqI+CbwzappfzxG22tzr78OfH0S9ZlZE+nu7qazs/OMPnp33TS3SV+MNbPp48QF166uLvbv3097ezsbN270hdgmV7OP/lxzH72Z2cRNqo/ezMzObw56M7PEOejNzBLnoDczS5yD3swscU13142kAeDxousAZgNPFV1Ek/CxOMXH4hQfi1Oa4VgsiIhRf0Om6YK+WUgqj3Wr0nTjY3GKj8UpPhanNPuxcNeNmVniHPRmZolz0I9tS9EFNBEfi1N8LE7xsTilqY+F++jNzBLnM3ozs8Q56KtI2ibpiKSHi66lSJLmS+qVtE/SXkkfLLqmokiaJekfJX0/OxZ3FF1T0SS1ZM+C/t9F11IkST+R9ANJeyQ17a8xuuumiqQ3Ac8CfxkRHUXXUxRJlwKXRsSDki4CdgM3RcS+gks75yQJeElEPCtpJtAHfDAiHii4tMJI+ghQAi6OiLcVXU9RssenliKi6Hvox+Uz+ioR8W1g2j8FKyKeiIgHs9f/SuXpYnOLraoYUfFsNjozG6btGZKkecBvA18ouharj4PeapK0ELgK+F6xlRQn66rYAxwB7ouIaXssgDuBjwEvFF1IEwjgW5J2S1pTdDFjcdDbuCS9lMrjID8UEc8UXU9RImIkIq4E5gFLJE3Lbj1JbwOORMTuomtpEksj4vXAW4D3Z12/TcdBb2PK+qO/DnwlIv666HqaQUQ8DfQCy4uupSDXADdmfdPbgd+U9OViSypORBzO/j0C/A2wpNiKRuegt1FlFyC3Avsj4jNF11MkSXMkvSx7/WLgOuCHxVZVjIi4LSLmRcRCYCVwf0S8s+CyCiHpJdmNCkh6CXA90JR36znoq0jqAb4LvFpSv6TOomsqyDXA71M5Y9uTDW8tuqiCXAr0SnoI2EWlj35a31ZoALwC6JP0feAfgb+NiL8vuKZR+fZKM7PE+YzezCxxDnozs8Q56M3MEuegNzNLnIPezCxxDnozs8Q56M3MEuegNzNL3P8Hhe52UZfhsKYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "9QUvzIeNr0HR",
        "outputId": "aedb5363-a3db-4a49-c512-d160ce187057"
      },
      "source": [
        "pd.DataFrame([experiment_1, experiment_2, experiment_3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>knn</th>\n",
              "      <th>SVC</th>\n",
              "      <th>decision_tree</th>\n",
              "      <th>Naive Bayes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.66841</td>\n",
              "      <td>0.69403</td>\n",
              "      <td>0.596339</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.66841</td>\n",
              "      <td>0.69403</td>\n",
              "      <td>0.591574</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.634456</td>\n",
              "      <td>0.66960</td>\n",
              "      <td>0.70119</td>\n",
              "      <td>0.581975</td>\n",
              "      <td>0.587272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   LogisticRegression      knn      SVC  decision_tree  Naive Bayes\n",
              "0            0.642212  0.66841  0.69403       0.596339     0.582007\n",
              "1            0.642212  0.66841  0.69403       0.591574     0.582007\n",
              "2            0.634456  0.66960  0.70119       0.581975     0.587272"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtJpfLblfN2F"
      },
      "source": [
        "# Experiment 4: Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCHdXg7V6Jl4"
      },
      "source": [
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "from keras import metrics, Input\n",
        "METRICS = [\n",
        "    metrics.RootMeanSquaredError(name='rms'),\n",
        "    metrics.MeanAbsoluteError(name='mae')\n",
        "]\n",
        "ENCODING_DIM = 500 #Desired Dimension\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "def make_and_train_autoencoder(X_train, metrics=METRICS):\n",
        "    \n",
        "    len_input_output = 7761\n",
        "    input_ = Input(shape=(len_input_output,))\n",
        "    encoded = Dense(units=ENCODING_DIM*2, activation=\"relu\")(input_)\n",
        "    bottleneck = Dense(units=ENCODING_DIM, activation=\"relu\")(encoded)\n",
        "    decoded = Dense(units=ENCODING_DIM*2, activation=\"relu\")(bottleneck)\n",
        "    output = Dense(units=len_input_output, activation=\"linear\")(decoded)\n",
        "    #Training is performed on the entire autoencoder\n",
        "    autoencoder = Model(inputs=input_, outputs=output)\n",
        "    autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=[metrics])\n",
        "    autoencoder.fit(X_train, X_train,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS)\n",
        "    #Use only the encoder part for dimensionality reduction\n",
        "    encoder = Model(inputs=input_, outputs=bottleneck)\n",
        "    return autoencoder, encoder"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-iJTr4w6Qh1",
        "outputId": "73c55d7c-d243-40c6-b978-50cc83e3c065"
      },
      "source": [
        "autoencoder, encoder = make_and_train_autoencoder(x)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "53/53 [==============================] - 9s 170ms/step - loss: 0.2153 - rms: 0.4640 - mae: 0.1685\n",
            "Epoch 2/50\n",
            "53/53 [==============================] - 8s 153ms/step - loss: 0.0895 - rms: 0.2991 - mae: 0.0978\n",
            "Epoch 3/50\n",
            "53/53 [==============================] - 10s 183ms/step - loss: 0.0643 - rms: 0.2535 - mae: 0.0917\n",
            "Epoch 4/50\n",
            "53/53 [==============================] - 9s 173ms/step - loss: 0.0597 - rms: 0.2444 - mae: 0.0918\n",
            "Epoch 5/50\n",
            "53/53 [==============================] - 8s 156ms/step - loss: 0.0555 - rms: 0.2355 - mae: 0.0866\n",
            "Epoch 6/50\n",
            "53/53 [==============================] - 8s 156ms/step - loss: 0.0522 - rms: 0.2285 - mae: 0.0825\n",
            "Epoch 7/50\n",
            "53/53 [==============================] - 9s 161ms/step - loss: 0.0498 - rms: 0.2232 - mae: 0.0790\n",
            "Epoch 8/50\n",
            "53/53 [==============================] - 9s 165ms/step - loss: 0.0479 - rms: 0.2189 - mae: 0.0788\n",
            "Epoch 9/50\n",
            "53/53 [==============================] - 8s 145ms/step - loss: 0.0457 - rms: 0.2139 - mae: 0.0771\n",
            "Epoch 10/50\n",
            "53/53 [==============================] - 8s 151ms/step - loss: 0.0444 - rms: 0.2106 - mae: 0.0765\n",
            "Epoch 11/50\n",
            "53/53 [==============================] - 8s 151ms/step - loss: 0.0431 - rms: 0.2076 - mae: 0.0760\n",
            "Epoch 12/50\n",
            "53/53 [==============================] - 8s 153ms/step - loss: 0.0415 - rms: 0.2037 - mae: 0.0737\n",
            "Epoch 13/50\n",
            "53/53 [==============================] - 8s 154ms/step - loss: 0.0407 - rms: 0.2018 - mae: 0.0735\n",
            "Epoch 14/50\n",
            "53/53 [==============================] - 9s 166ms/step - loss: 0.0395 - rms: 0.1987 - mae: 0.0737\n",
            "Epoch 15/50\n",
            "53/53 [==============================] - 8s 152ms/step - loss: 0.0383 - rms: 0.1957 - mae: 0.0713\n",
            "Epoch 16/50\n",
            "53/53 [==============================] - 8s 152ms/step - loss: 0.0375 - rms: 0.1936 - mae: 0.0717\n",
            "Epoch 17/50\n",
            "53/53 [==============================] - 8s 145ms/step - loss: 0.0363 - rms: 0.1906 - mae: 0.0700\n",
            "Epoch 18/50\n",
            "53/53 [==============================] - 8s 146ms/step - loss: 0.0356 - rms: 0.1886 - mae: 0.0699\n",
            "Epoch 19/50\n",
            "53/53 [==============================] - 8s 153ms/step - loss: 0.0349 - rms: 0.1867 - mae: 0.0688\n",
            "Epoch 20/50\n",
            "53/53 [==============================] - 8s 153ms/step - loss: 0.0339 - rms: 0.1842 - mae: 0.0673\n",
            "Epoch 21/50\n",
            "53/53 [==============================] - 8s 152ms/step - loss: 0.0333 - rms: 0.1824 - mae: 0.0676\n",
            "Epoch 22/50\n",
            "53/53 [==============================] - 9s 160ms/step - loss: 0.0324 - rms: 0.1799 - mae: 0.0660\n",
            "Epoch 23/50\n",
            "53/53 [==============================] - 8s 149ms/step - loss: 0.0319 - rms: 0.1786 - mae: 0.0660\n",
            "Epoch 24/50\n",
            "53/53 [==============================] - 8s 144ms/step - loss: 0.0311 - rms: 0.1762 - mae: 0.0651\n",
            "Epoch 25/50\n",
            "53/53 [==============================] - 8s 145ms/step - loss: 0.0303 - rms: 0.1740 - mae: 0.0642\n",
            "Epoch 26/50\n",
            "53/53 [==============================] - 8s 153ms/step - loss: 0.0305 - rms: 0.1746 - mae: 0.0646\n",
            "Epoch 27/50\n",
            "53/53 [==============================] - 8s 153ms/step - loss: 0.0313 - rms: 0.1770 - mae: 0.0669\n",
            "Epoch 28/50\n",
            "53/53 [==============================] - 8s 161ms/step - loss: 0.0299 - rms: 0.1729 - mae: 0.0646\n",
            "Epoch 29/50\n",
            "53/53 [==============================] - 10s 179ms/step - loss: 0.0285 - rms: 0.1688 - mae: 0.0623\n",
            "Epoch 30/50\n",
            "53/53 [==============================] - 9s 175ms/step - loss: 0.0278 - rms: 0.1667 - mae: 0.0612\n",
            "Epoch 31/50\n",
            "53/53 [==============================] - 8s 153ms/step - loss: 0.0271 - rms: 0.1646 - mae: 0.0603\n",
            "Epoch 32/50\n",
            "53/53 [==============================] - 8s 146ms/step - loss: 0.0263 - rms: 0.1623 - mae: 0.0587\n",
            "Epoch 33/50\n",
            "53/53 [==============================] - 8s 147ms/step - loss: 0.0262 - rms: 0.1619 - mae: 0.0590\n",
            "Epoch 34/50\n",
            "53/53 [==============================] - 9s 169ms/step - loss: 0.0259 - rms: 0.1608 - mae: 0.0593\n",
            "Epoch 35/50\n",
            "53/53 [==============================] - 8s 153ms/step - loss: 0.0251 - rms: 0.1584 - mae: 0.0578\n",
            "Epoch 36/50\n",
            "53/53 [==============================] - 9s 167ms/step - loss: 0.0246 - rms: 0.1570 - mae: 0.0573\n",
            "Epoch 37/50\n",
            "53/53 [==============================] - 9s 161ms/step - loss: 0.0244 - rms: 0.1561 - mae: 0.0567\n",
            "Epoch 38/50\n",
            "53/53 [==============================] - 8s 147ms/step - loss: 0.0243 - rms: 0.1557 - mae: 0.0563\n",
            "Epoch 39/50\n",
            "53/53 [==============================] - 9s 172ms/step - loss: 0.0241 - rms: 0.1553 - mae: 0.0565\n",
            "Epoch 40/50\n",
            "53/53 [==============================] - 11s 204ms/step - loss: 0.0232 - rms: 0.1522 - mae: 0.0557\n",
            "Epoch 41/50\n",
            "53/53 [==============================] - 8s 148ms/step - loss: 0.0231 - rms: 0.1519 - mae: 0.0568\n",
            "Epoch 42/50\n",
            "53/53 [==============================] - 8s 154ms/step - loss: 0.0228 - rms: 0.1511 - mae: 0.0554\n",
            "Epoch 43/50\n",
            "53/53 [==============================] - 9s 168ms/step - loss: 0.0224 - rms: 0.1497 - mae: 0.0543\n",
            "Epoch 44/50\n",
            "53/53 [==============================] - 9s 173ms/step - loss: 0.0222 - rms: 0.1489 - mae: 0.0550\n",
            "Epoch 45/50\n",
            "53/53 [==============================] - 8s 148ms/step - loss: 0.0221 - rms: 0.1485 - mae: 0.0556\n",
            "Epoch 46/50\n",
            "53/53 [==============================] - 8s 156ms/step - loss: 0.0213 - rms: 0.1460 - mae: 0.0538\n",
            "Epoch 47/50\n",
            "53/53 [==============================] - 9s 173ms/step - loss: 0.0208 - rms: 0.1443 - mae: 0.0528\n",
            "Epoch 48/50\n",
            "53/53 [==============================] - 9s 166ms/step - loss: 0.0204 - rms: 0.1427 - mae: 0.0519\n",
            "Epoch 49/50\n",
            "53/53 [==============================] - 10s 188ms/step - loss: 0.0201 - rms: 0.1419 - mae: 0.0515\n",
            "Epoch 50/50\n",
            "53/53 [==============================] - 8s 147ms/step - loss: 0.0208 - rms: 0.1442 - mae: 0.0520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2HRfFEkfA"
      },
      "source": [
        "x_encoded_data = encoder(x).numpy()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVspL5BJF3-t",
        "outputId": "8da6016a-a470-48c1-f4c8-0f19e5952878"
      },
      "source": [
        "x_encoded_data.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5fD7DDdbGJJn",
        "outputId": "f4f5cecb-b3f0-41f3-83a9-6f02ad4f887b"
      },
      "source": [
        "# Spotcheck and compare algorithms with out applying feature scale.......\n",
        "n_neighbors=5\n",
        "\n",
        "# keeping all models in one list\n",
        "models=[]\n",
        "models.append(('LogisticRegression',LogisticRegression()))\n",
        "models.append(('knn',KNeighborsClassifier(n_neighbors=n_neighbors)))\n",
        "models.append(('SVC',SVC()))\n",
        "models.append((\"decision_tree\",DecisionTreeClassifier()))\n",
        "models.append(('Naive Bayes',GaussianNB()))\n",
        "\n",
        "# Evaluating Each model\n",
        "predictions=[]\n",
        "error='accuracy'\n",
        "experiment_4 = {}\n",
        "for name,model in models:\n",
        "    fold=KFold(n_splits=10)\n",
        "    result=cross_val_score(model,x_encoded_data,y,cv=fold,scoring=error)\n",
        "    predictions.append(result)\n",
        "    experiment_4[name] = result.mean()\n",
        "    \n",
        "# Visualizing the Model accuracy\n",
        "fig=plt.figure()\n",
        "fig.suptitle(\"Comparing Algorithms\")\n",
        "plt.boxplot(predictions)\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "HVUKUzD_ww69",
        "outputId": "0e4eb8c5-0c66-466d-f672-5e0db60cfff8"
      },
      "source": [
        "pd.DataFrame([experiment_1, experiment_2, experiment_3, experiment_4])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>knn</th>\n",
              "      <th>SVC</th>\n",
              "      <th>decision_tree</th>\n",
              "      <th>Naive Bayes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.668410</td>\n",
              "      <td>0.694030</td>\n",
              "      <td>0.596339</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.668410</td>\n",
              "      <td>0.694030</td>\n",
              "      <td>0.591574</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.634456</td>\n",
              "      <td>0.669600</td>\n",
              "      <td>0.701190</td>\n",
              "      <td>0.581975</td>\n",
              "      <td>0.587272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.671429</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.695862</td>\n",
              "      <td>0.581373</td>\n",
              "      <td>0.673820</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   LogisticRegression       knn       SVC  decision_tree  Naive Bayes\n",
              "0            0.642212  0.668410  0.694030       0.596339     0.582007\n",
              "1            0.642212  0.668410  0.694030       0.591574     0.582007\n",
              "2            0.634456  0.669600  0.701190       0.581975     0.587272\n",
              "3            0.671429  0.654762  0.695862       0.581373     0.673820"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vh-znTi6RIc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}