{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "RNA_mutation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "Gw-yP26j0kdL"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUBZ8mzx0kdQ"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "",
        "_uuid": "",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcYu4KKV0kdR",
        "outputId": "f47bc538-737b-43a2-971a-267e10c5846e"
      },
      "source": [
        "dataset = pd.read_csv(\"METABRIC_RNA_Mutation.csv\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (179,189,191,193) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBVsenUX0kdS"
      },
      "source": [
        "# Describing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "QwVh9Mxp0kdS",
        "outputId": "ba90859a-7800-486d-a771-70d7c069fe18"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type_of_breast_surgery</th>\n",
              "      <th>cancer_type</th>\n",
              "      <th>cancer_type_detailed</th>\n",
              "      <th>cellularity</th>\n",
              "      <th>pam50_+_claudin-low_subtype</th>\n",
              "      <th>er_status_measured_by_ihc</th>\n",
              "      <th>er_status</th>\n",
              "      <th>neoplasm_histologic_grade</th>\n",
              "      <th>her2_status_measured_by_snp6</th>\n",
              "      <th>her2_status</th>\n",
              "      <th>tumor_other_histologic_subtype</th>\n",
              "      <th>hormone_therapy</th>\n",
              "      <th>inferred_menopausal_state</th>\n",
              "      <th>integrative_cluster</th>\n",
              "      <th>primary_tumor_laterality</th>\n",
              "      <th>oncotree_code</th>\n",
              "      <th>overall_survival</th>\n",
              "      <th>pr_status</th>\n",
              "      <th>radio_therapy</th>\n",
              "      <th>3-gene_classifier_subtype</th>\n",
              "      <th>tumor_stage</th>\n",
              "      <th>pik3ca_mut</th>\n",
              "      <th>tp53_mut</th>\n",
              "      <th>muc16_mut</th>\n",
              "      <th>ahnak2_mut</th>\n",
              "      <th>kmt2c_mut</th>\n",
              "      <th>syne1_mut</th>\n",
              "      <th>gata3_mut</th>\n",
              "      <th>map3k1_mut</th>\n",
              "      <th>ahnak_mut</th>\n",
              "      <th>dnah11_mut</th>\n",
              "      <th>cdh1_mut</th>\n",
              "      <th>dnah2_mut</th>\n",
              "      <th>kmt2d_mut</th>\n",
              "      <th>ush2a_mut</th>\n",
              "      <th>ryr2_mut</th>\n",
              "      <th>dnah5_mut</th>\n",
              "      <th>herc2_mut</th>\n",
              "      <th>pde4dip_mut</th>\n",
              "      <th>akap9_mut</th>\n",
              "      <th>...</th>\n",
              "      <th>hsd17b1</th>\n",
              "      <th>hsd17b10</th>\n",
              "      <th>hsd17b11</th>\n",
              "      <th>hsd17b12</th>\n",
              "      <th>hsd17b13</th>\n",
              "      <th>hsd17b14</th>\n",
              "      <th>hsd17b2</th>\n",
              "      <th>hsd17b3</th>\n",
              "      <th>hsd17b4</th>\n",
              "      <th>hsd17b6</th>\n",
              "      <th>hsd17b7</th>\n",
              "      <th>hsd17b8</th>\n",
              "      <th>hsd3b1</th>\n",
              "      <th>hsd3b2</th>\n",
              "      <th>hsd3b7</th>\n",
              "      <th>mecom</th>\n",
              "      <th>met</th>\n",
              "      <th>ncoa2</th>\n",
              "      <th>nrip1</th>\n",
              "      <th>pik3r3</th>\n",
              "      <th>prkci</th>\n",
              "      <th>prkd1</th>\n",
              "      <th>ran</th>\n",
              "      <th>rdh5</th>\n",
              "      <th>sdc4</th>\n",
              "      <th>serpini1</th>\n",
              "      <th>shbg</th>\n",
              "      <th>slc29a1</th>\n",
              "      <th>sox9</th>\n",
              "      <th>spry2</th>\n",
              "      <th>srd5a1</th>\n",
              "      <th>srd5a2</th>\n",
              "      <th>srd5a3</th>\n",
              "      <th>st7</th>\n",
              "      <th>star</th>\n",
              "      <th>tnk2</th>\n",
              "      <th>tulp4</th>\n",
              "      <th>ugt2b15</th>\n",
              "      <th>ugt2b17</th>\n",
              "      <th>ugt2b7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MASTECTOMY</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Invasive Ductal Carcinoma</td>\n",
              "      <td>NaN</td>\n",
              "      <td>claudin-low</td>\n",
              "      <td>Positve</td>\n",
              "      <td>Positive</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Ductal/NST</td>\n",
              "      <td>1</td>\n",
              "      <td>Post</td>\n",
              "      <td>4ER+</td>\n",
              "      <td>Right</td>\n",
              "      <td>IDC</td>\n",
              "      <td>1</td>\n",
              "      <td>Negative</td>\n",
              "      <td>1</td>\n",
              "      <td>ER-/HER2-</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2581</td>\n",
              "      <td>-0.0487</td>\n",
              "      <td>1.6822</td>\n",
              "      <td>1.7409</td>\n",
              "      <td>8.8731</td>\n",
              "      <td>-0.6494</td>\n",
              "      <td>0.4931</td>\n",
              "      <td>1.0860</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>-1.8717</td>\n",
              "      <td>-1.7598</td>\n",
              "      <td>0.5445</td>\n",
              "      <td>0.5018</td>\n",
              "      <td>0.7345</td>\n",
              "      <td>-0.9899</td>\n",
              "      <td>1.1211</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>-0.3421</td>\n",
              "      <td>0.4076</td>\n",
              "      <td>-0.6199</td>\n",
              "      <td>-1.2582</td>\n",
              "      <td>1.8407</td>\n",
              "      <td>0.6630</td>\n",
              "      <td>5.0109</td>\n",
              "      <td>0.5008</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>-0.4357</td>\n",
              "      <td>0.9859</td>\n",
              "      <td>1.2386</td>\n",
              "      <td>2.8796</td>\n",
              "      <td>-1.1877</td>\n",
              "      <td>-0.0194</td>\n",
              "      <td>-1.6345</td>\n",
              "      <td>-0.2142</td>\n",
              "      <td>-0.5698</td>\n",
              "      <td>-1.1741</td>\n",
              "      <td>-1.4779</td>\n",
              "      <td>-0.5954</td>\n",
              "      <td>-0.8847</td>\n",
              "      <td>-0.3354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BREAST CONSERVING</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Invasive Ductal Carcinoma</td>\n",
              "      <td>High</td>\n",
              "      <td>LumA</td>\n",
              "      <td>Positve</td>\n",
              "      <td>Positive</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Ductal/NST</td>\n",
              "      <td>1</td>\n",
              "      <td>Pre</td>\n",
              "      <td>4ER+</td>\n",
              "      <td>Right</td>\n",
              "      <td>IDC</td>\n",
              "      <td>1</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>ER+/HER2- High Prolif</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>H178P</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.4467</td>\n",
              "      <td>-0.0693</td>\n",
              "      <td>-0.7837</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>1.5355</td>\n",
              "      <td>0.7590</td>\n",
              "      <td>-0.5652</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>-1.2693</td>\n",
              "      <td>1.0729</td>\n",
              "      <td>1.1973</td>\n",
              "      <td>-2.9847</td>\n",
              "      <td>-1.9199</td>\n",
              "      <td>0.6433</td>\n",
              "      <td>-0.4801</td>\n",
              "      <td>-1.8732</td>\n",
              "      <td>-1.0840</td>\n",
              "      <td>-0.7220</td>\n",
              "      <td>-0.1878</td>\n",
              "      <td>-1.0623</td>\n",
              "      <td>1.7653</td>\n",
              "      <td>0.3500</td>\n",
              "      <td>-0.2505</td>\n",
              "      <td>-0.6337</td>\n",
              "      <td>-0.1047</td>\n",
              "      <td>0.0222</td>\n",
              "      <td>-0.2938</td>\n",
              "      <td>-1.0821</td>\n",
              "      <td>-1.3206</td>\n",
              "      <td>0.2446</td>\n",
              "      <td>-0.4412</td>\n",
              "      <td>0.4534</td>\n",
              "      <td>0.4068</td>\n",
              "      <td>0.7634</td>\n",
              "      <td>0.0231</td>\n",
              "      <td>0.9121</td>\n",
              "      <td>-0.9538</td>\n",
              "      <td>-0.2264</td>\n",
              "      <td>0.5398</td>\n",
              "      <td>-0.8920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MASTECTOMY</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Invasive Ductal Carcinoma</td>\n",
              "      <td>High</td>\n",
              "      <td>LumB</td>\n",
              "      <td>Positve</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Ductal/NST</td>\n",
              "      <td>1</td>\n",
              "      <td>Pre</td>\n",
              "      <td>3</td>\n",
              "      <td>Right</td>\n",
              "      <td>IDC</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>H1047R</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.6253</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>1.6822</td>\n",
              "      <td>0.8981</td>\n",
              "      <td>-0.0943</td>\n",
              "      <td>1.1599</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.1493</td>\n",
              "      <td>0.1117</td>\n",
              "      <td>1.6262</td>\n",
              "      <td>2.2685</td>\n",
              "      <td>-0.9910</td>\n",
              "      <td>0.1767</td>\n",
              "      <td>-0.9128</td>\n",
              "      <td>-0.0006</td>\n",
              "      <td>0.7079</td>\n",
              "      <td>-0.7401</td>\n",
              "      <td>1.2279</td>\n",
              "      <td>-0.2882</td>\n",
              "      <td>-0.1727</td>\n",
              "      <td>1.1257</td>\n",
              "      <td>0.8306</td>\n",
              "      <td>0.2707</td>\n",
              "      <td>-0.7554</td>\n",
              "      <td>-0.3559</td>\n",
              "      <td>-0.7735</td>\n",
              "      <td>-0.1387</td>\n",
              "      <td>-0.9122</td>\n",
              "      <td>1.2552</td>\n",
              "      <td>0.4593</td>\n",
              "      <td>-0.5381</td>\n",
              "      <td>0.0668</td>\n",
              "      <td>0.8344</td>\n",
              "      <td>1.7227</td>\n",
              "      <td>0.4024</td>\n",
              "      <td>-3.7172</td>\n",
              "      <td>-1.5538</td>\n",
              "      <td>1.3701</td>\n",
              "      <td>-0.1078</td>\n",
              "      <td>0.3655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MASTECTOMY</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Mixed Ductal and Lobular Carcinoma</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>LumB</td>\n",
              "      <td>Positve</td>\n",
              "      <td>Positive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>1</td>\n",
              "      <td>Pre</td>\n",
              "      <td>9</td>\n",
              "      <td>Right</td>\n",
              "      <td>MDLC</td>\n",
              "      <td>1</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>E542K</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.8189</td>\n",
              "      <td>0.0960</td>\n",
              "      <td>1.4099</td>\n",
              "      <td>-0.6707</td>\n",
              "      <td>-0.3589</td>\n",
              "      <td>-0.8998</td>\n",
              "      <td>-0.5063</td>\n",
              "      <td>0.2546</td>\n",
              "      <td>-0.6586</td>\n",
              "      <td>1.7024</td>\n",
              "      <td>0.1617</td>\n",
              "      <td>1.4208</td>\n",
              "      <td>0.1320</td>\n",
              "      <td>1.8754</td>\n",
              "      <td>-1.8850</td>\n",
              "      <td>0.1474</td>\n",
              "      <td>0.5097</td>\n",
              "      <td>-0.0393</td>\n",
              "      <td>-0.2049</td>\n",
              "      <td>-0.3290</td>\n",
              "      <td>3.2140</td>\n",
              "      <td>2.4162</td>\n",
              "      <td>1.7962</td>\n",
              "      <td>-1.2505</td>\n",
              "      <td>-0.1742</td>\n",
              "      <td>-0.2858</td>\n",
              "      <td>-0.7305</td>\n",
              "      <td>-1.0178</td>\n",
              "      <td>-0.7887</td>\n",
              "      <td>1.3361</td>\n",
              "      <td>-0.5630</td>\n",
              "      <td>-0.7078</td>\n",
              "      <td>0.8228</td>\n",
              "      <td>0.6819</td>\n",
              "      <td>-0.1948</td>\n",
              "      <td>-2.3286</td>\n",
              "      <td>-0.9924</td>\n",
              "      <td>-0.3154</td>\n",
              "      <td>0.2320</td>\n",
              "      <td>-0.4828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MASTECTOMY</td>\n",
              "      <td>Breast Cancer</td>\n",
              "      <td>Breast Mixed Ductal and Lobular Carcinoma</td>\n",
              "      <td>High</td>\n",
              "      <td>LumB</td>\n",
              "      <td>Positve</td>\n",
              "      <td>Positive</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>Negative</td>\n",
              "      <td>Mixed</td>\n",
              "      <td>1</td>\n",
              "      <td>Post</td>\n",
              "      <td>9</td>\n",
              "      <td>Right</td>\n",
              "      <td>MDLC</td>\n",
              "      <td>0</td>\n",
              "      <td>Positive</td>\n",
              "      <td>1</td>\n",
              "      <td>ER+/HER2- High Prolif</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>S241F</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.0590</td>\n",
              "      <td>0.2796</td>\n",
              "      <td>0.0493</td>\n",
              "      <td>-0.7074</td>\n",
              "      <td>0.0696</td>\n",
              "      <td>-0.4491</td>\n",
              "      <td>-0.5634</td>\n",
              "      <td>-0.7627</td>\n",
              "      <td>-0.7051</td>\n",
              "      <td>0.6065</td>\n",
              "      <td>-0.0141</td>\n",
              "      <td>0.7040</td>\n",
              "      <td>-2.0938</td>\n",
              "      <td>-0.1260</td>\n",
              "      <td>-0.6658</td>\n",
              "      <td>0.6451</td>\n",
              "      <td>0.5497</td>\n",
              "      <td>4.1999</td>\n",
              "      <td>0.2832</td>\n",
              "      <td>0.4018</td>\n",
              "      <td>0.1308</td>\n",
              "      <td>-0.5351</td>\n",
              "      <td>1.2930</td>\n",
              "      <td>1.2971</td>\n",
              "      <td>-0.8885</td>\n",
              "      <td>-0.5545</td>\n",
              "      <td>0.0266</td>\n",
              "      <td>0.5328</td>\n",
              "      <td>0.1858</td>\n",
              "      <td>-0.3201</td>\n",
              "      <td>-0.5845</td>\n",
              "      <td>-0.3544</td>\n",
              "      <td>-1.0150</td>\n",
              "      <td>2.2961</td>\n",
              "      <td>0.1817</td>\n",
              "      <td>-0.1572</td>\n",
              "      <td>0.0427</td>\n",
              "      <td>5.0048</td>\n",
              "      <td>3.8476</td>\n",
              "      <td>1.3223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 688 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  type_of_breast_surgery    cancer_type  ... ugt2b17  ugt2b7\n",
              "0             MASTECTOMY  Breast Cancer  ... -0.8847 -0.3354\n",
              "1      BREAST CONSERVING  Breast Cancer  ...  0.5398 -0.8920\n",
              "2             MASTECTOMY  Breast Cancer  ... -0.1078  0.3655\n",
              "3             MASTECTOMY  Breast Cancer  ...  0.2320 -0.4828\n",
              "4             MASTECTOMY  Breast Cancer  ...  3.8476  1.3223\n",
              "\n",
              "[5 rows x 688 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JKPH-Xc0kdT",
        "outputId": "94e01a54-5983-497e-8301-fde07190e553"
      },
      "source": [
        "print(dataset.shape)\n",
        "dataset.dtypes"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1904, 688)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type_of_breast_surgery          object\n",
              "cancer_type                     object\n",
              "cancer_type_detailed            object\n",
              "cellularity                     object\n",
              "pam50_+_claudin-low_subtype     object\n",
              "                                ...   \n",
              "tnk2                           float64\n",
              "tulp4                          float64\n",
              "ugt2b15                        float64\n",
              "ugt2b17                        float64\n",
              "ugt2b7                         float64\n",
              "Length: 688, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Yz1z-xWCnj"
      },
      "source": [
        "# Check missing value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bD4t9whSa56",
        "outputId": "ca80c509-aefd-4d10-a66e-4f9678d889df"
      },
      "source": [
        "miss_value = {}\n",
        "for column in dataset.columns:\n",
        "  count = dataset[column].isnull().sum()\n",
        "  if count >0:\n",
        "    miss_value[column] = count\n",
        "\n",
        "print(miss_value)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'type_of_breast_surgery': 22, 'cancer_type_detailed': 15, 'cellularity': 54, 'er_status_measured_by_ihc': 30, 'neoplasm_histologic_grade': 72, 'tumor_other_histologic_subtype': 15, 'primary_tumor_laterality': 106, 'oncotree_code': 15, '3-gene_classifier_subtype': 204, 'tumor_stage': 501, 'mutation_count': 45, 'tumor_size': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVqEL8sQ5Mz5"
      },
      "source": [
        "# Drop missing value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqV5cY-iE9IJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f534eb-0ffc-46b0-fcc8-350a5c306144"
      },
      "source": [
        "dataset = dataset.drop(['3-gene_classifier_subtype','tumor_stage','primary_tumor_laterality'],axis='columns')\n",
        "dataset.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1904, 685)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIXc-Jl90kdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9f9f1b-ad59-40dc-95a2-a71098888f05"
      },
      "source": [
        "dataset = dataset.dropna(axis='rows')\n",
        "dataset.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677, 685)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cal0JcGyWXs0"
      },
      "source": [
        "# Create target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZmBC2F8Rtij"
      },
      "source": [
        "y = dataset['overall_survival']\n",
        "dataset = dataset.drop('overall_survival', axis ='columns')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui7tG2im5WdH"
      },
      "source": [
        "# Check type of value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoGXzZBi1b-c",
        "outputId": "aa7f4d62-f2f3-418b-d3e1-bea357580377"
      },
      "source": [
        "dataset['smarcb1_mut'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       878\n",
              "0       798\n",
              "I28L      1\n",
              "Name: smarcb1_mut, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDYr01S30kdV"
      },
      "source": [
        "list_cat = []\n",
        "for column in dataset.columns:\n",
        "    if column == 'age_at_diagnosis':\n",
        "      break\n",
        "    else:\n",
        "      list_cat.append(column)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1shoIDbK0kdV"
      },
      "source": [
        "for column in list_cat:\n",
        "    dataset[column] = dataset[column].replace([0],'0')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STPpoZP4WweF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50b68d0-47c1-457b-98bf-1990be89845e"
      },
      "source": [
        "dataset['smarcb1_mut'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1676\n",
              "I28L       1\n",
              "Name: smarcb1_mut, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnpoBkKp5gLD"
      },
      "source": [
        "# Create clean dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3OziE6R0kdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1895cee2-3560-44df-9924-53efbf2d4f2d"
      },
      "source": [
        "dataset_new = pd.get_dummies(dataset,columns=list_cat)\n",
        "dataset_new.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677, 7761)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xea-2oGC0kdX"
      },
      "source": [
        "dataset_new = dataset_new.astype(np.float16)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeQzUyVi2JBg"
      },
      "source": [
        "# Create feature and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTqQdBnb0kdY",
        "outputId": "2ec249fc-9df6-4914-9973-7e2ccdcc0e07"
      },
      "source": [
        "x = dataset_new.values\n",
        "x.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677, 7761)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEIUYaAp0kdZ",
        "outputId": "1174733f-aba3-41f3-d4d8-821b62ff60a9"
      },
      "source": [
        "labelencoder= LabelEncoder()\n",
        "y = labelencoder.fit_transform(y)\n",
        "y.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ3ibAI82ad-"
      },
      "source": [
        "# Split train and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYKv4mZF0kdZ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoXyO6pnYhVm"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2l9Q9Gb0kdZ",
        "outputId": "5648f77d-cc26-4206-e880-5008a4053d5c"
      },
      "source": [
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(X_train, y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wfjr2xnQ0kda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41d161b-c387-42aa-d94a-d6e5ac98e982"
      },
      "source": [
        "y_pred = svclassifier.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[155  41]\n",
            " [ 61  79]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.79      0.75       196\n",
            "           1       0.66      0.56      0.61       140\n",
            "\n",
            "    accuracy                           0.70       336\n",
            "   macro avg       0.69      0.68      0.68       336\n",
            "weighted avg       0.69      0.70      0.69       336\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0h2fREQZg87"
      },
      "source": [
        "# Experiment 1: without scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jl82MB880kdd",
        "outputId": "11f61133-906e-4868-dbe3-5bc607fbf506"
      },
      "source": [
        "# keeping all models in one list\n",
        "models=[]\n",
        "models.append(('LogisticRegression',LogisticRegression()))\n",
        "models.append(('knn',KNeighborsClassifier(n_neighbors=5)))\n",
        "models.append(('SVC',SVC()))\n",
        "models.append((\"decision_tree\",DecisionTreeClassifier()))\n",
        "models.append(('Naive Bayes',GaussianNB()))\n",
        "\n",
        "# Evaluating Each model\n",
        "predictions=[]\n",
        "experiment_1 = {}\n",
        "error='accuracy'\n",
        "for name,model in models:\n",
        "    fold=KFold(n_splits=10)\n",
        "    result=cross_val_score(model,x,y,cv=fold,scoring=error)\n",
        "    predictions.append(result)\n",
        "    experiment_1[name] = result.mean()\n",
        "\n",
        "# Visualizing the Model accuracy\n",
        "fig=plt.figure()\n",
        "fig.suptitle(\"Comparing Algorithms\")\n",
        "plt.boxplot(predictions)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "asvdn2mln3pa",
        "outputId": "e843a6d5-b697-4ab6-c468-228443ae774f"
      },
      "source": [
        "\n",
        "pd.DataFrame([experiment_1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>knn</th>\n",
              "      <th>SVC</th>\n",
              "      <th>decision_tree</th>\n",
              "      <th>Naive Bayes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.66841</td>\n",
              "      <td>0.69403</td>\n",
              "      <td>0.596339</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   LogisticRegression      knn      SVC  decision_tree  Naive Bayes\n",
              "0            0.642212  0.66841  0.69403       0.596339     0.582007"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZiJO1E70kde"
      },
      "source": [
        "# Experiment 2: with scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "diflib2H0kde",
        "outputId": "798f24c0-f1cb-45d5-e109-98e6951c0a50"
      },
      "source": [
        "# Spot Checking and Comparing Algorithms With StandardScaler Scaler\n",
        "pipelines=[]\n",
        "pipelines.append(('scaled Logisitic Regression',Pipeline([('scaler',StandardScaler()),('LogisticRegression',LogisticRegression())])))\n",
        "pipelines.append(('scaled KNN',Pipeline([('scaler',StandardScaler()),('KNN',KNeighborsClassifier(n_neighbors=5))])))\n",
        "pipelines.append(('scaled SVC',Pipeline([('scaler',StandardScaler()),('SVC',SVC())])))\n",
        "pipelines.append(('scaled DecisionTree',Pipeline([('scaler',StandardScaler()),('decision',DecisionTreeClassifier())])))\n",
        "pipelines.append(('scaled naive bayes',Pipeline([('scaler',StandardScaler()),('scaled Naive Bayes',GaussianNB())])))\n",
        "\n",
        "# Evaluating Each model\n",
        "predictions=[]\n",
        "experiment_2 = {}\n",
        "for name,model in models:\n",
        "    fold=KFold(n_splits=10)\n",
        "    result=cross_val_score(model,x,y,cv=fold,scoring=error)\n",
        "    predictions.append(result)\n",
        "    experiment_2[name] = result.mean()\n",
        "\n",
        "# Visualizing the Model accuracy\n",
        "fig=plt.figure()\n",
        "fig.suptitle(\"Comparing Algorithms\")\n",
        "plt.boxplot(predictions)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:216: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(x, axis, dtype, out, keepdims)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "gkCGWd3ZqbU5",
        "outputId": "95c682eb-422b-4c27-a589-3cb78f6e23eb"
      },
      "source": [
        "pd.DataFrame([experiment_1, experiment_2])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>knn</th>\n",
              "      <th>SVC</th>\n",
              "      <th>decision_tree</th>\n",
              "      <th>Naive Bayes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.66841</td>\n",
              "      <td>0.69403</td>\n",
              "      <td>0.596339</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.66841</td>\n",
              "      <td>0.69403</td>\n",
              "      <td>0.591574</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   LogisticRegression      knn      SVC  decision_tree  Naive Bayes\n",
              "0            0.642212  0.66841  0.69403       0.596339     0.582007\n",
              "1            0.642212  0.66841  0.69403       0.591574     0.582007"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U648U3U8ZwTX"
      },
      "source": [
        "# Experiment 3: dimensional reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMqwHqwy-mOg"
      },
      "source": [
        "pca = PCA(n_components=500)\n",
        "new_x = pca.fit_transform(x)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abEcyz7K-0M-",
        "outputId": "4d39a627-91e0-47ad-a53e-4a173c76dccf"
      },
      "source": [
        "sum = 0\n",
        "for i in pca.explained_variance_ratio_:\n",
        "  sum = sum +i\n",
        "\n",
        "print(\"Overall variation :\", sum)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall variation : 0.992588985266454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW0P9EyD_DV9",
        "outputId": "4d777d88-0414-4488-8a73-d0815b070d97"
      },
      "source": [
        "new_x.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Cd-YKQEg_tV2",
        "outputId": "e84c1de1-ef67-4617-88fa-5d04cc6746e6"
      },
      "source": [
        "# Spotcheck and compare algorithms with out applying feature scale.......\n",
        "n_neighbors=5\n",
        "\n",
        "# keeping all models in one list\n",
        "models=[]\n",
        "models.append(('LogisticRegression',LogisticRegression()))\n",
        "models.append(('knn',KNeighborsClassifier(n_neighbors=n_neighbors)))\n",
        "models.append(('SVC',SVC()))\n",
        "models.append((\"decision_tree\",DecisionTreeClassifier()))\n",
        "models.append(('Naive Bayes',GaussianNB()))\n",
        "\n",
        "# Evaluating Each model\n",
        "predictions=[]\n",
        "error='accuracy'\n",
        "experiment_3 = {}\n",
        "for name,model in models:\n",
        "    fold=KFold(n_splits=10)\n",
        "    result=cross_val_score(model,new_x,y,cv=fold,scoring=error)\n",
        "    predictions.append(result)\n",
        "    experiment_3[name] = result.mean()\n",
        "\n",
        "# Visualizing the Model accuracy\n",
        "fig=plt.figure()\n",
        "fig.suptitle(\"Comparing Algorithms\")\n",
        "plt.boxplot(predictions)\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "9QUvzIeNr0HR",
        "outputId": "aedb5363-a3db-4a49-c512-d160ce187057"
      },
      "source": [
        "pd.DataFrame([experiment_1, experiment_2, experiment_3])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>knn</th>\n",
              "      <th>SVC</th>\n",
              "      <th>decision_tree</th>\n",
              "      <th>Naive Bayes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.66841</td>\n",
              "      <td>0.69403</td>\n",
              "      <td>0.596339</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.66841</td>\n",
              "      <td>0.69403</td>\n",
              "      <td>0.591574</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.634456</td>\n",
              "      <td>0.66960</td>\n",
              "      <td>0.70119</td>\n",
              "      <td>0.581975</td>\n",
              "      <td>0.587272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   LogisticRegression      knn      SVC  decision_tree  Naive Bayes\n",
              "0            0.642212  0.66841  0.69403       0.596339     0.582007\n",
              "1            0.642212  0.66841  0.69403       0.591574     0.582007\n",
              "2            0.634456  0.66960  0.70119       0.581975     0.587272"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtJpfLblfN2F"
      },
      "source": [
        "# Experiment 4: Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhDwtYrIfI9X"
      },
      "source": [
        "latent_dim = 500 \n",
        "\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.latent_dim = latent_dim   \n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Dense(4000, activation='relu',input_shape=(7761,)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Dense(2000, activation='relu'),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Dense(1000, activation='relu'),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Dense(latent_dim, activation='relu'),\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(1000, activation='relu',input_shape=(latent_dim,)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.Dense(2000, activation='relu'), \n",
        "      layers.BatchNormalization(), \n",
        "      layers.Dense(4000, activation='relu'), \n",
        "      layers.BatchNormalization(),                                       \n",
        "      layers.Dense(7761 , activation='tanh'),\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K5mfjOTgYuK"
      },
      "source": [
        "autoencoder = Autoencoder(latent_dim)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmBsyycKi1GU"
      },
      "source": [
        "from keras import metrics, Input\n",
        "metrics = [\n",
        "    metrics.RootMeanSquaredError(name='rms'),\n",
        "    metrics.MeanAbsoluteError(name='mae')\n",
        "]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRXPCifggZH2"
      },
      "source": [
        "autoencoder.compile(optimizer='RMSprop', loss='mean_squared_error', metrics=[metrics])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iqUY2NRgdbe",
        "outputId": "ccc2ae7c-fed4-4686-a289-7fa64e2bab9d"
      },
      "source": [
        "autoencoder.fit(X_train, X_train,\n",
        "                epochs=20,\n",
        "                shuffle=True,\n",
        "                validation_data=(X_test, X_test))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "42/42 [==============================] - 47s 1s/step - loss: 1.0365 - rms: 1.0181 - mae: 0.5501 - val_loss: 1.7110 - val_rms: 1.3080 - val_mae: 0.9979\n",
            "Epoch 2/20\n",
            "42/42 [==============================] - 45s 1s/step - loss: 0.8344 - rms: 0.9135 - mae: 0.3502 - val_loss: 1.0292 - val_rms: 1.0145 - val_mae: 0.4902\n",
            "Epoch 3/20\n",
            "42/42 [==============================] - 43s 1s/step - loss: 0.8037 - rms: 0.8965 - mae: 0.2962 - val_loss: 1.3377 - val_rms: 1.1566 - val_mae: 0.6909\n",
            "Epoch 4/20\n",
            "42/42 [==============================] - 43s 1s/step - loss: 0.7461 - rms: 0.8638 - mae: 0.2192 - val_loss: 0.8683 - val_rms: 0.9318 - val_mae: 0.3742\n",
            "Epoch 5/20\n",
            "42/42 [==============================] - 45s 1s/step - loss: 0.7397 - rms: 0.8601 - mae: 0.2065 - val_loss: 1.1398 - val_rms: 1.0676 - val_mae: 0.5194\n",
            "Epoch 6/20\n",
            "42/42 [==============================] - 42s 994ms/step - loss: 0.7218 - rms: 0.8496 - mae: 0.1671 - val_loss: 1.4333 - val_rms: 1.1972 - val_mae: 0.7647\n",
            "Epoch 7/20\n",
            "42/42 [==============================] - 40s 939ms/step - loss: 0.7028 - rms: 0.8383 - mae: 0.1324 - val_loss: 1.3393 - val_rms: 1.1573 - val_mae: 0.7005\n",
            "Epoch 8/20\n",
            "42/42 [==============================] - 42s 986ms/step - loss: 0.7197 - rms: 0.8483 - mae: 0.1541 - val_loss: 1.1351 - val_rms: 1.0654 - val_mae: 0.5476\n",
            "Epoch 9/20\n",
            "42/42 [==============================] - 42s 1s/step - loss: 0.7165 - rms: 0.8465 - mae: 0.1576 - val_loss: 0.8004 - val_rms: 0.8946 - val_mae: 0.2448\n",
            "Epoch 10/20\n",
            "42/42 [==============================] - 41s 982ms/step - loss: 0.7332 - rms: 0.8563 - mae: 0.1774 - val_loss: 0.9404 - val_rms: 0.9697 - val_mae: 0.3712\n",
            "Epoch 11/20\n",
            "42/42 [==============================] - 41s 980ms/step - loss: 0.7035 - rms: 0.8388 - mae: 0.1322 - val_loss: 0.6827 - val_rms: 0.8263 - val_mae: 0.1079\n",
            "Epoch 12/20\n",
            "42/42 [==============================] - 43s 1s/step - loss: 0.6995 - rms: 0.8363 - mae: 0.1228 - val_loss: 0.6881 - val_rms: 0.8295 - val_mae: 0.1320\n",
            "Epoch 13/20\n",
            "42/42 [==============================] - 42s 991ms/step - loss: 0.7065 - rms: 0.8406 - mae: 0.1484 - val_loss: 0.6886 - val_rms: 0.8298 - val_mae: 0.1337\n",
            "Epoch 14/20\n",
            "42/42 [==============================] - 42s 1s/step - loss: 0.7245 - rms: 0.8512 - mae: 0.1791 - val_loss: 0.9248 - val_rms: 0.9617 - val_mae: 0.4364\n",
            "Epoch 15/20\n",
            "42/42 [==============================] - 42s 1s/step - loss: 0.7250 - rms: 0.8515 - mae: 0.1826 - val_loss: 1.1172 - val_rms: 1.0570 - val_mae: 0.5300\n",
            "Epoch 16/20\n",
            "42/42 [==============================] - 42s 999ms/step - loss: 0.7076 - rms: 0.8412 - mae: 0.1537 - val_loss: 1.0536 - val_rms: 1.0264 - val_mae: 0.5211\n",
            "Epoch 17/20\n",
            "42/42 [==============================] - 41s 981ms/step - loss: 0.6972 - rms: 0.8350 - mae: 0.1293 - val_loss: 1.0612 - val_rms: 1.0302 - val_mae: 0.5204\n",
            "Epoch 18/20\n",
            "42/42 [==============================] - 41s 973ms/step - loss: 0.7127 - rms: 0.8442 - mae: 0.1438 - val_loss: 0.8490 - val_rms: 0.9214 - val_mae: 0.3098\n",
            "Epoch 19/20\n",
            "42/42 [==============================] - 41s 970ms/step - loss: 0.7063 - rms: 0.8404 - mae: 0.1305 - val_loss: 0.6943 - val_rms: 0.8332 - val_mae: 0.1211\n",
            "Epoch 20/20\n",
            "42/42 [==============================] - 40s 962ms/step - loss: 0.6943 - rms: 0.8333 - mae: 0.1119 - val_loss: 0.6864 - val_rms: 0.8285 - val_mae: 0.1599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2002882810>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mja2HRfFEkfA"
      },
      "source": [
        "x_encoded_data = autoencoder.encoder(x).numpy()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVspL5BJF3-t",
        "outputId": "bb678d80-2e84-485f-f348-7c22b3cffbd6"
      },
      "source": [
        "x_encoded_data.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1677, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5fD7DDdbGJJn",
        "outputId": "6680c9cc-0af3-4419-be1d-d491dbb4b82a"
      },
      "source": [
        "# Spotcheck and compare algorithms with out applying feature scale.......\n",
        "n_neighbors=5\n",
        "\n",
        "# keeping all models in one list\n",
        "models=[]\n",
        "models.append(('LogisticRegression',LogisticRegression()))\n",
        "models.append(('knn',KNeighborsClassifier(n_neighbors=n_neighbors)))\n",
        "models.append(('SVC',SVC()))\n",
        "models.append((\"decision_tree\",DecisionTreeClassifier()))\n",
        "models.append(('Naive Bayes',GaussianNB()))\n",
        "\n",
        "# Evaluating Each model\n",
        "predictions=[]\n",
        "error='accuracy'\n",
        "experiment_4 = {}\n",
        "for name,model in models:\n",
        "    fold=KFold(n_splits=10)\n",
        "    result=cross_val_score(model,x_encoded_data,y,cv=fold,scoring=error)\n",
        "    predictions.append(result)\n",
        "    experiment_4[name] = result.mean()\n",
        "    \n",
        "# Visualizing the Model accuracy\n",
        "fig=plt.figure()\n",
        "fig.suptitle(\"Comparing Algorithms\")\n",
        "plt.boxplot(predictions)\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEVCAYAAADuAi4fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYIklEQVR4nO3df7BfdX3n8efLyy+riMnmqjQJJJZg04kK+i26C1rsFoiuQ2idoUGt4ESxO4YqdLSw2AWjdGlnVGbddCpqVjtKoktb9rrdLjJDWDcOtPlGo0IQDBFKIsiFhFpafiThtX98zyWHy82935v7Tc43n+/rMXMm33PO55zzPufevL7nfs75nq9sExER5XpR0wVERMTBlaCPiChcgj4ionAJ+oiIwiXoIyIKl6CPiChcgj6KIek9kr7d0La/IunTB2ndk+6XpDMlbT8Y244yJOjjBSS9W1Jb0hOSHpL0d5LOaLquqdj+uu2zD+Y2JN0maZekow/mdurG75ckSzrpUG0/Dn8J+ngeSZcB1wF/ArwSOAH4c2BZk3VNRdIRh2AbC4C3AAbOPdjbq7Z50Pcrypegj+dIOg5YBXzY9l/b/hfbu21/y/bHqjZHS7pO0s+q4bqxs9uxLgRJH5f0SPXXwHmS3iHpXkk7Jf2n2vaulnSjpG9I+mdJ35P0+tr8yyXdV83bIum3a/MukvRdSZ+T9BhwdTVtQ62NJf2+pJ9IelzSakmq5g1J+oykRyX9VNLKqv1kwfo+4A7gK8CFUxzLj1f7/zNJH6ifhUs6TtJfShqV9ICkT0h6UTf7Jek71SZ+UP3F9bu1bf5h7bi/vzb9K5L+vPrL7Ilq/a+qfna7JP1Y0qm19n8kaUd13O+R9O8n29fofwn6qPu3wDHA30zS5krgzcApwOuB04BP1Oa/qlrHXOA/A18E3gu8kc7Z8B9LWlhrvwz4H8Bs4AbgJklHVvPuq5Y5Dvgk8DVJx9eWfROwjc5fHtfsp953Ar8OvA44Hzinmv5B4O3VfrwBOG+SfR7zPuDr1XCOpFdO1EjSUuAy4LeAk4AzxzX5fLVPrwZ+o1rv+2vz97tftt9avXy97Zfa/kY1/qpqnXOBFcBqSbNqi55P5+c0B3gauB34XjV+I/DZqvbXACuBX7d9LJ3jdf/+D0kcFmxnyIBtgPcAD0/R5j7gHbXxc4D7q9dnAk8CQ9X4sXS6Od5Ua78JOK96fTVwR23ei4CHgLfsZ9ubgWXV64uAfxw3/yJgQ23cwBm18W8Cl1evbwU+VJv3W1X7I/az7TOA3cCcavzHwKW1+V8BPl29XgP8l9q8k6p1nwQMAc8Av1ab/yHgtmnu10m18bHjfkRt2iPAm2u1fbE27xLg7tr4a4HHa7U+Uh2PI5v+nczQmyFn9FH3GDBniu6LXwYeqI0/UE17bh2291avn6z+/Xlt/pPAS2vjD469sP0ssH1sfZLeJ2lz1e3yOLCEzhnoC5adxMO11/9a2/Yvj1t+qnVdCHzb9qPV+A3sv/tmsnXPAY7khcdw7jRqmchjtvfUxuv7Ci/8GUz4M7G9FfgonTfhRyStk1T/+cZhKEEfdbfT+bN+sm6MnwEn1sZPqKYdqPljL6p+6nnAzySdSKfbZyXwb2y/HLgTUG3ZmTx69aFqWy+oYzxJL6bT9fEbkh6W9DBwKfD6+jWFLtf9KJ2/DMYfwx218UYfKWv7Bttn0KnRwJ82WU/MXII+nmP7n+j0q6+uLqL+kqQjJb1d0p9VzdYCn5A0LGlO1f5rM9jsGyX9TvVXxEfpvNHcAbyETsiMAlQXF5fMYDvjfRP4iKS5kl4O/NEkbc8D9gK/RqdP/xRgMfD/6PSvT7Tu90taLOmXgD8em1H9tfNN4BpJx1ZvaJcxvWP4czr9+z0n6TWSfrO6wP4UnbP9Zw/GtuLQSdDH89j+DJ3g+QSdkH2Qzln1TVWTTwNt4IfAj+hc0JvJB4X+J/C7wC7g94DfcedOny3AZ+j8lfFzOv3I353Bdsb7IvBtOvvxfeB/A3voBPp4FwL/3fY/2n54bAD+G/Ce8V1dtv8O+K/AemArnTcu6LyJQaeP/F/oXHDdQKcbaM00ar8a+GrVpXX+NJbrxtHAtXT+8ngYeAVwRY+3EYeY7HzxSDRD0tV0Liq+tw9qeTvwF7ZPnLLx9Ne9mE6309Hj+tEjDomc0cdAkvTi6v7+IyTNBa5i8ttKp7v+31bnMwez6PRxfyshH01J0MegEp1783fR6bq5m871hl75EJ3bFO+j0x30H3u47ohpSddNREThckYfEVG4BH1EROES9BERhUvQR0QULkEfEVG4BH1EROES9BERhUvQR0QULkEfEVG4BH1EROES9BERhUvQR0QULkEfEVG4BH1EROGOmLrJoTVnzhwvWLCg6TIiIg4rmzZtetT28ETz+i7oFyxYQLvdbrqMiIjDiqQH9jcvXTcREYVL0EdEFC5BHxFRuAR9REThEvQREYVL0I+zdu1alixZwtDQEEuWLGHt2rVNlxQRMSN9d3tlk9auXcuVV17Jl7/8Zc444ww2bNjAihUrALjgggsari4i4sDIdtM1PE+r1XJT99EvWbKEz3/+87ztbW97btr69eu55JJLuPPOOxupKSKiG5I22W5NOC9Bv8/Q0BBPPfUURx555HPTdu/ezTHHHMPevXsbqSkiohuTBX366GsWL17Mhg0bnjdtw4YNLF68uKGKIiJmLkFfc+WVV7JixQrWr1/P7t27Wb9+PStWrODKK69surSIiAOWi7E1YxdcL7nkEu6++24WL17MNddckwuxEXFYSx99REQB0kcfETHAEvQREYVL0EdEFK6roJe0VNI9krZKunyC+Z+TtLka7pX0eG3e3tq8kV4WHxERU5vyrhtJQ8Bq4CxgO7BR0ojtLWNtbF9aa38JcGptFU/aPqV3JUdExHR0c0Z/GrDV9jbbzwDrgGWTtL8AyJPAIiL6RDdBPxd4sDa+vZr2ApJOBBYCt9YmHyOpLekOSeftZ7mLqzbt0dHRLkuPiIhu9Ppi7HLgRtv1B8OcWN3b+W7gOkm/Mn4h29fbbtluDQ9P+CXmERFxgLoJ+h3A/Nr4vGraRJYzrtvG9o7q323AbTy//z4iIg6yboJ+I7BI0kJJR9EJ8xfcPSPpV4FZwO21abMkHV29ngOcDmwZv2xERBw8U951Y3uPpJXAzcAQsMb2XZJWAW3bY6G/HFjn5z9TYTHwBUnP0nlTubZ+t05ERBx8edZNREQB8qybiIgBlqCPiChcgj4ionAJ+oiIwiXoIyIKl6CPiChcgj4ionAJ+oiIwiXoIyIKl6CPiChcgj4ionAJ+oiIwiXoIyIKl6CPiChcgj4ionAJ+oiIwiXoIyIKl6CPiChcgj4ionAJ+oiIwiXoIyIK11XQS1oq6R5JWyVdPsH8z0naXA33Snq8Nu9CST+phgt7WXxEREztiKkaSBoCVgNnAduBjZJGbG8Za2P70lr7S4BTq9ezgauAFmBgU7Xsrp7uRURE7Fc3Z/SnAVttb7P9DLAOWDZJ+wuAtdXrc4BbbO+swv0WYOlMCo6IiOnpJujnAg/WxrdX015A0onAQuDW6Swr6WJJbUnt0dHRbuqOiIgu9fpi7HLgRtt7p7OQ7ettt2y3hoeHe1xSRMRgm7KPHtgBzK+Nz6umTWQ58OFxy545btnbui8vDgVJM16H7R5U0qxeHAco41hEWbo5o98ILJK0UNJRdMJ8ZHwjSb8KzAJur02+GThb0ixJs4Czq2nRR2xPOnTb5nA31T4O0rGIskx5Rm97j6SVdAJ6CFhj+y5Jq4C27bHQXw6sc+033fZOSZ+i82YBsMr2zt7uQkRETEb9dgbSarXcbrebLiNqJOVMtZJjEf1K0ibbrYnm5ZOxERGFS9BHRBQuQR8RUbgEfURE4bq5jz4iYmCV8PmKBH1ExCS6Ceh+vxsrXTcREYVL0EdEFC5BHxFRuAR9REThEvQREYVL0EdEFC5BHxFRuAR9REThEvQREYVL0EdEFC5BHxFRuAR9REThEvQREYVL0EdEFC5BHxFRuK6CXtJSSfdI2irp8v20OV/SFkl3SbqhNn2vpM3VMNKrwiMiojtTfvGIpCFgNXAWsB3YKGnE9pZam0XAFcDptndJekVtFU/aPqXHdUdERJe6OaM/Ddhqe5vtZ4B1wLJxbT4IrLa9C8D2I70tMyIiDlQ3QT8XeLA2vr2aVncycLKk70q6Q9LS2rxjJLWr6edNtAFJF1dt2qOjo9PagYiImFyvvjP2CGARcCYwD/iOpNfafhw40fYOSa8GbpX0I9v31Re2fT1wPUCr1erfL16MiDgMdXNGvwOYXxufV02r2w6M2N5t+6fAvXSCH9s7qn+3AbcBp86w5oiImIZugn4jsEjSQklHAcuB8XfP3ETnbB5Jc+h05WyTNEvS0bXppwNbiIiIQ2bKrhvbeyStBG4GhoA1tu+StApo2x6p5p0taQuwF/iY7cck/TvgC5KepfOmcm39bp2IiDj4ZPdXl3ir1XK73W66jKiRRL/9nhyI2bNns2vXrqbLYNasWezcubPpMqKH+uH/iKRNtlsTzevVxdjDjqQZr6PpH2xMz65du/riZ9aL372I6RjYoJ/qP3w/vENHRPRCnnUTEVG4BH1EROES9BERhUvQR0QULkEfEVG4BH1EROGKDPrZs2cjaUYDMON1zJ49u+EjERFR6H30+WBMRMQ+RZ7RR0TEPgn6iIjCJegjIgqXoI+IKFyCPiIG2iDcpVfkXTcREd0ahLv0ckYfEVG4BH1EROGK7LrxVS+Dq49ruoxOHRERDSsy6PXJX/RNn5uvbrqKiBh06bqJiChcV0EvaamkeyRtlXT5ftqcL2mLpLsk3VCbfqGkn1TDhb0qPCIiujNl142kIWA1cBawHdgoacT2llqbRcAVwOm2d0l6RTV9NnAV0AIMbKqW3dX7XYmIiIl0c0Z/GrDV9jbbzwDrgGXj2nwQWD0W4LYfqaafA9xie2c17xZgaW9Kj4iIbnQT9HOBB2vj26tpdScDJ0v6rqQ7JC2dxrIREXEQ9equmyOARcCZwDzgO5Je2+3Cki4GLgY44YQTelRSRERAd2f0O4D5tfF51bS67cCI7d22fwrcSyf4u1kW29fbbtluDQ8PT6f+mMIgPMcjIibXTdBvBBZJWijpKGA5MDKuzU10zuaRNIdOV8424GbgbEmzJM0Czq6mxSEy9hyPpoddu3L9/XAy0zf2+klCNG/KrhvbeyStpBPQQ8Aa23dJWgW0bY+wL9C3AHuBj9l+DEDSp+i8WQCssr3zYOxIRPRONx84lNQXH0yMqanfflCtVsvtdntG6+iXX8B+qKMfauiXOvqhhn6qY6ayH/1Vh6RNtlsTzcsnYyMiCpegj4goXII+IqJwCfqIAZTbbgdLkY8pjojJDcLX58U+OaOPiChcgj4ionAJ+oiIwiXoIyIKl6CPiChcgj4ionC5vTIGhq96GVx9XNNldOqIOIQS9DEw9Mlf9M2947666SpikKTrJiKicAn6iIjCJegjIgqXoI+IKFyCPiKicAn6iIjCFXt7ZT88/nTWrFlNlxARUWbQ9+Je6X75wuDorZwAxCDqqutG0lJJ90jaKunyCeZfJGlU0uZq+EBt3t7a9JFeFh8xHbZnPPRiPTt37mz4SMSgmfKMXtIQsBo4C9gObJQ0YnvLuKbfsL1yglU8afuUmZcaByIf+4+IbrpuTgO22t4GIGkdsAwYH/TRh/Kx/5hITgAGSzdBPxd4sDa+HXjTBO3eJemtwL3ApbbHljlGUhvYA1xr+6aZFBwRM5cTgMHSq9srvwUssP064Bbgq7V5J9puAe8GrpP0K+MXlnSxpLak9ujoaI9KiogI6C7odwDza+PzqmnPsf2Y7aer0S8Bb6zN21H9uw24DTh1/AZsX2+7Zbs1PDw8rR2IiIjJddN1sxFYJGkhnYBfTufs/DmSjrf9UDV6LnB3NX0W8K+2n5Y0Bzgd+LNeFR8RMVODcL1iyqC3vUfSSuBmYAhYY/suSauAtu0R4A8knUunH34ncFG1+GLgC5KepfPXw7UT3K0TEdGYQbheoX7YwbpWq+V2u910GcV8YKpf9qNf6pip7Ed5dfRDDb2oQ9Km6nroC+RZNxERhUvQR0QULkEfEVG4BH1EROES9BERhUvQR0QULkEfEVG4Ir94JCKmli9hGRwJ+ogBlG9hGyzpuomIKFyCPiKicAn6iIjCJegjIgqXi7EDIHdXRAy2BH3hcndFRKTrJiKicAN7Rt9Nd8ZUbXKWGxGHg4EN+oR0RAyKdN1ERBQuQR8RUbgEfURE4RL0ERGF6yroJS2VdI+krZIun2D+RZJGJW2uhg/U5l0o6SfVcGEvi4+IiKlNedeNpCFgNXAWsB3YKGnE9pZxTb9he+W4ZWcDVwEtwMCmatldPak+IiKm1M0Z/WnAVtvbbD8DrAOWdbn+c4BbbO+swv0WYOmBlRoREQeim6CfCzxYG99eTRvvXZJ+KOlGSfOns6ykiyW1JbVHR0e7LD0iIrrRq4ux3wIW2H4dnbP2r05nYdvX227Zbg0PD/eopIiIgO6CfgcwvzY+r5r2HNuP2X66Gv0S8MZul42IaJqkxoeD+YTXbh6BsBFYJGkhnZBeDry73kDS8bYfqkbPBe6uXt8M/ImksT04G7hixlVHRPTIIDzhdcqgt71H0ko6oT0ErLF9l6RVQNv2CPAHks4F9gA7gYuqZXdK+hSdNwuAVbZ3HoT9iBnIA94iyqZ++w/aarXcbrebLiNiQv1+5nYo5Vjs0w/HQtIm262J5uWTsRERhUvQR0QULkEfEVG4BH1EROES9BERhRvYrxKMiP3r5pbbbto1fSdKdCToI+IFEtBlSddNREThEvQREYVL0EdEFC5BHxFRuAR9REThEvQREYVL0EdEFC5BHxFRuAR9REThEvQREYVL0EdEFC5BHxFRuAR9REThEvQREYXrKuglLZV0j6Stki6fpN27JFlSqxpfIOlJSZur4S96VXhERHRnyufRSxoCVgNnAduBjZJGbG8Z1+5Y4CPA349bxX22T+lRvRERMU3dnNGfBmy1vc32M8A6YNkE7T4F/CnwVA/ri4iIGeom6OcCD9bGt1fTniPpDcB82387wfILJX1f0v+V9JaJNiDpYkltSe3R0dFua4+IiC7M+GKspBcBnwX+cILZDwEn2D4VuAy4QdLLxjeyfb3tlu3W8PDwTEuKiIiaboJ+BzC/Nj6vmjbmWGAJcJuk+4E3AyOSWraftv0YgO1NwH3Ayb0oPCIiutNN0G8EFklaKOkoYDkwMjbT9j/ZnmN7ge0FwB3Aubbbkoari7lIejWwCNjW872IiIj9mvKuG9t7JK0EbgaGgDW275K0CmjbHplk8bcCqyTtBp4Fft/2zl4UHhFxKEjqSTvbvSjngKjJjU+k1Wq53W43XUbEhCQ1+h82Yn8kbbLdmmjelGf0EYOihDO3iIkk6CMqCegoVZ51ExFRuAR9REThEvQREYVL0EdEFC5BHxFRuAR9REThEvQREYVL0EdEFK7vHoEgaRR4oOk6gDnAo00X0SdyLPbJsdgnx2KffjgWJ9qe8DnvfRf0/UJSe3/PjRg0ORb75Fjsk2OxT78fi3TdREQULkEfEVG4BP3+Xd90AX0kx2KfHIt9ciz26etjkT76iIjC5Yw+IqJwCfpxJK2R9IikO5uupUmS5ktaL2mLpLskfaTpmpoi6RhJ/yDpB9Wx+GTTNTVN0pCk70v6X03X0iRJ90v6kaTNkvr2q/HSdTOOpLcCTwB/aXtJ0/U0RdLxwPG2vyfpWGATcJ7tLQ2Xdsip85VSL7H9hKQjgQ3AR2zf0XBpjZF0GdACXmb7nU3X0xRJ9wMt203fQz+pnNGPY/s7wMB/gbnth2x/r3r9z8DdwNxmq2qGO56oRo+shoE9Q5I0D/gPwJeariW6k6CPKUlaAJwK/H2zlTSn6qrYDDwC3GJ7YI8FcB3wceDZpgvpAwa+LWmTpIubLmZ/EvQxKUkvBf4K+KjtXzRdT1Ns77V9CjAPOE3SQHbrSXon8IjtTU3X0ifOsP0G4O3Ah6uu376ToI/9qvqj/wr4uu2/brqefmD7cWA9sLTpWhpyOnBu1Te9DvhNSV9rtqTm2N5R/fsI8DfAac1WNLEEfUyougD5ZeBu259tup4mSRqW9PLq9YuBs4AfN1tVM2xfYXue7QXAcuBW2+9tuKxGSHpJdaMCkl4CnA305d16CfpxJK0FbgdeI2m7pBVN19SQ04Hfo3PGtrka3tF0UQ05Hlgv6YfARjp99AN9W2EA8Epgg6QfAP8A/K3t/9NwTRPK7ZUREYXLGX1EROES9BERhUvQR0QULkEfEVG4BH1EROES9BERhUvQR0QULkEfEVG4/w8hfxw9gq0KSAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "HVUKUzD_ww69",
        "outputId": "ea70e8ab-b632-443c-d331-087ae8942edd"
      },
      "source": [
        "pd.DataFrame([experiment_1, experiment_2, experiment_3, experiment_4])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LogisticRegression</th>\n",
              "      <th>knn</th>\n",
              "      <th>SVC</th>\n",
              "      <th>decision_tree</th>\n",
              "      <th>Naive Bayes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.668410</td>\n",
              "      <td>0.694030</td>\n",
              "      <td>0.596339</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.642212</td>\n",
              "      <td>0.668410</td>\n",
              "      <td>0.694030</td>\n",
              "      <td>0.591574</td>\n",
              "      <td>0.582007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.634456</td>\n",
              "      <td>0.669600</td>\n",
              "      <td>0.701190</td>\n",
              "      <td>0.581975</td>\n",
              "      <td>0.587272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.605774</td>\n",
              "      <td>0.565868</td>\n",
              "      <td>0.582004</td>\n",
              "      <td>0.553924</td>\n",
              "      <td>0.554477</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   LogisticRegression       knn       SVC  decision_tree  Naive Bayes\n",
              "0            0.642212  0.668410  0.694030       0.596339     0.582007\n",
              "1            0.642212  0.668410  0.694030       0.591574     0.582007\n",
              "2            0.634456  0.669600  0.701190       0.581975     0.587272\n",
              "3            0.605774  0.565868  0.582004       0.553924     0.554477"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}